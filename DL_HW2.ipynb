{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/soroush-abbasi/289L_AdvDL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYHKyiBXkaBJ",
        "outputId": "11150771-0f3e-44ae-9f19-f10da3e43ef5"
      },
      "id": "vYHKyiBXkaBJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '289L_AdvDL'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 14 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (14/14), 14.33 KiB | 4.78 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd 289L_AdvDL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egXptTg9kfmg",
        "outputId": "0fd06421-be1e-4137-a9f0-6ec75e591e0f"
      },
      "id": "egXptTg9kfmg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/289L_AdvDL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm==0.5.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GuJmcGcGmSP",
        "outputId": "2edf9045-8c3e-44ea-91db-4d75bd293ffd",
        "collapsed": true
      },
      "id": "_GuJmcGcGmSP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==0.5.4\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/431.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/431.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.5.4) (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4->timm==0.5.4)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.5.4) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->timm==0.5.4)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.5.4) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.5.4) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.5.4) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.5.4) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7507140",
      "metadata": {
        "id": "e7507140"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from timm.models import create_model\n",
        "\n",
        "from engine import train_one_epoch, train_one_epoch_distillation, evaluate\n",
        "from utils import get_training_dataloader, get_test_dataloader\n",
        "import models"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UqQPv5tur1CV"
      },
      "id": "UqQPv5tur1CV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1"
      ],
      "metadata": {
        "id": "SxhD0_t5r5l4"
      },
      "id": "SxhD0_t5r5l4"
    },
    {
      "cell_type": "code",
      "source": [
        "MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "CHECKPOINT_PATH = './checkpoint'\n",
        "MODEL_NAME = 'vit_base_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "shots = 1000\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=False,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "cifar10_training_loader = get_training_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=2,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    shots=shots\n",
        ")\n",
        "\n",
        "assert (shots*num_classes == len(cifar10_training_loader.dataset))\n",
        "\n",
        "cifar10_test_loader = get_test_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=4,\n",
        "    batch_size=256,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQmqf1qFr1AC",
        "outputId": "e1510c08-d058-4920-d4c0-8cda3035f9ea"
      },
      "id": "TQmqf1qFr1AC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_base_patch16_224\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13322896.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "number of params: 86567656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "\n",
        "    train_stats = evaluate(cifar10_training_loader, model, criterion, device)\n",
        "    test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "    print(f\"Accuracy of the network on the {len(cifar10_training_loader)} train images: {train_stats['acc1']:.1f}%\")\n",
        "    print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM6GPPWJr09p",
        "outputId": "8cb0552e-df59-4745-ef53-fec7730b17a9"
      },
      "id": "zM6GPPWJr09p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:10:12  loss: 7.3936 (7.3936)  time: 0.9807  data: 0.1432  max mem: 2096\n",
            "Epoch: [1]  [100/625]  eta: 0:00:57  loss: 2.0924 (2.5162)  time: 0.0999  data: 0.0034  max mem: 3067\n",
            "Epoch: [1]  [200/625]  eta: 0:00:44  loss: 1.9737 (2.3078)  time: 0.1000  data: 0.0037  max mem: 3067\n",
            "Epoch: [1]  [300/625]  eta: 0:00:33  loss: 2.0648 (2.2227)  time: 0.1004  data: 0.0036  max mem: 3067\n",
            "Epoch: [1]  [400/625]  eta: 0:00:23  loss: 1.9214 (2.1639)  time: 0.1009  data: 0.0036  max mem: 3067\n",
            "Epoch: [1]  [500/625]  eta: 0:00:12  loss: 2.0792 (2.1346)  time: 0.1015  data: 0.0036  max mem: 3067\n",
            "Epoch: [1]  [600/625]  eta: 0:00:02  loss: 1.9556 (2.1012)  time: 0.1020  data: 0.0037  max mem: 3067\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 1.8628 (2.0936)  time: 0.1018  data: 0.0036  max mem: 3067\n",
            "Epoch: [1] Total time: 0:01:03 (0.1022 s / it)\n",
            "Averaged stats: loss: 1.8628 (2.0936)\n",
            "Test:  [  0/625]  eta: 0:03:13  loss: 1.7258 (1.7258)  acc1: 37.5000 (37.5000)  acc5: 93.7500 (93.7500)  time: 0.3103  data: 0.0951  max mem: 3067\n",
            "Test:  [ 20/625]  eta: 0:00:26  loss: 1.9346 (1.9349)  acc1: 31.2500 (30.3571)  acc5: 87.5000 (83.3333)  time: 0.0297  data: 0.0033  max mem: 3067\n",
            "Test:  [ 40/625]  eta: 0:00:21  loss: 1.8593 (1.8955)  acc1: 37.5000 (31.0976)  acc5: 81.2500 (83.9939)  time: 0.0305  data: 0.0034  max mem: 3067\n",
            "Test:  [ 60/625]  eta: 0:00:19  loss: 1.8555 (1.8910)  acc1: 31.2500 (30.6352)  acc5: 81.2500 (83.1967)  time: 0.0301  data: 0.0033  max mem: 3067\n",
            "Test:  [ 80/625]  eta: 0:00:18  loss: 1.9504 (1.9061)  acc1: 25.0000 (29.3981)  acc5: 81.2500 (82.7160)  time: 0.0305  data: 0.0033  max mem: 3067\n",
            "Test:  [100/625]  eta: 0:00:17  loss: 2.0044 (1.9184)  acc1: 18.7500 (28.7748)  acc5: 81.2500 (82.2401)  time: 0.0300  data: 0.0033  max mem: 3067\n",
            "Test:  [120/625]  eta: 0:00:16  loss: 1.8388 (1.9186)  acc1: 31.2500 (29.0806)  acc5: 81.2500 (82.2314)  time: 0.0304  data: 0.0035  max mem: 3067\n",
            "Test:  [140/625]  eta: 0:00:15  loss: 1.9298 (1.9179)  acc1: 25.0000 (28.7234)  acc5: 81.2500 (82.4025)  time: 0.0301  data: 0.0033  max mem: 3067\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 1.9308 (1.9220)  acc1: 25.0000 (28.4161)  acc5: 81.2500 (82.4922)  time: 0.0304  data: 0.0033  max mem: 3067\n",
            "Test:  [180/625]  eta: 0:00:14  loss: 1.8235 (1.9104)  acc1: 31.2500 (28.8329)  acc5: 87.5000 (82.9420)  time: 0.0302  data: 0.0034  max mem: 3067\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 1.9525 (1.9181)  acc1: 25.0000 (28.6692)  acc5: 81.2500 (82.8980)  time: 0.0303  data: 0.0034  max mem: 3067\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 1.8612 (1.9137)  acc1: 25.0000 (28.7613)  acc5: 81.2500 (82.7771)  time: 0.0304  data: 0.0034  max mem: 3067\n",
            "Test:  [240/625]  eta: 0:00:12  loss: 1.8530 (1.9158)  acc1: 18.7500 (28.2676)  acc5: 87.5000 (82.8838)  time: 0.0301  data: 0.0034  max mem: 3067\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 1.9448 (1.9211)  acc1: 25.0000 (28.0651)  acc5: 87.5000 (83.0220)  time: 0.0307  data: 0.0036  max mem: 3067\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 1.9442 (1.9266)  acc1: 18.7500 (27.7802)  acc5: 81.2500 (82.6735)  time: 0.0301  data: 0.0034  max mem: 3067\n",
            "Test:  [300/625]  eta: 0:00:10  loss: 1.9263 (1.9300)  acc1: 25.0000 (27.5955)  acc5: 87.5000 (82.8073)  time: 0.0303  data: 0.0033  max mem: 3067\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 1.8235 (1.9267)  acc1: 31.2500 (27.8037)  acc5: 81.2500 (82.8466)  time: 0.0303  data: 0.0033  max mem: 3067\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 1.8250 (1.9210)  acc1: 31.2500 (28.0242)  acc5: 81.2500 (82.7896)  time: 0.0302  data: 0.0034  max mem: 3067\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 1.9442 (1.9223)  acc1: 31.2500 (28.0298)  acc5: 81.2500 (82.8601)  time: 0.0304  data: 0.0033  max mem: 3067\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 1.9654 (1.9239)  acc1: 25.0000 (28.0020)  acc5: 81.2500 (82.8576)  time: 0.0306  data: 0.0033  max mem: 3067\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 1.9106 (1.9220)  acc1: 25.0000 (27.9769)  acc5: 81.2500 (83.0268)  time: 0.0301  data: 0.0034  max mem: 3067\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 2.0123 (1.9249)  acc1: 25.0000 (27.8504)  acc5: 81.2500 (83.0612)  time: 0.0301  data: 0.0034  max mem: 3067\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 1.9881 (1.9282)  acc1: 25.0000 (27.7353)  acc5: 81.2500 (82.9649)  time: 0.0304  data: 0.0034  max mem: 3067\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 1.9265 (1.9272)  acc1: 31.2500 (27.9826)  acc5: 81.2500 (82.8227)  time: 0.0302  data: 0.0034  max mem: 3067\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 1.8614 (1.9286)  acc1: 31.2500 (28.0535)  acc5: 81.2500 (82.7573)  time: 0.0306  data: 0.0036  max mem: 3067\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 1.8192 (1.9260)  acc1: 25.0000 (28.0190)  acc5: 81.2500 (82.8094)  time: 0.0303  data: 0.0036  max mem: 3067\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 1.8059 (1.9221)  acc1: 25.0000 (28.0470)  acc5: 87.5000 (82.9415)  time: 0.0301  data: 0.0035  max mem: 3067\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 1.8061 (1.9194)  acc1: 31.2500 (28.1077)  acc5: 81.2500 (83.0291)  time: 0.0305  data: 0.0036  max mem: 3067\n",
            "Test:  [560/625]  eta: 0:00:02  loss: 1.9785 (1.9199)  acc1: 31.2500 (28.1974)  acc5: 81.2500 (82.9100)  time: 0.0303  data: 0.0036  max mem: 3067\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 1.7414 (1.9166)  acc1: 31.2500 (28.3563)  acc5: 81.2500 (82.9604)  time: 0.0305  data: 0.0037  max mem: 3067\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.7913 (1.9158)  acc1: 31.2500 (28.4734)  acc5: 81.2500 (83.0283)  time: 0.0303  data: 0.0037  max mem: 3067\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.8545 (1.9152)  acc1: 31.2500 (28.5125)  acc5: 81.2500 (83.0616)  time: 0.0304  data: 0.0036  max mem: 3067\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.7824 (1.9150)  acc1: 31.2500 (28.4900)  acc5: 87.5000 (83.0500)  time: 0.0304  data: 0.0035  max mem: 3067\n",
            "Test: Total time: 0:00:19 (0.0308 s / it)\n",
            "* Acc@1 28.490 Acc@5 83.050 loss 1.915\n",
            "Test:  [ 0/40]  eta: 0:00:49  loss: 1.9476 (1.9476)  acc1: 30.4688 (30.4688)  acc5: 82.4219 (82.4219)  time: 1.2440  data: 0.6420  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.9931 (1.9924)  acc1: 29.2969 (29.7433)  acc5: 83.2031 (83.2403)  time: 0.5442  data: 0.0310  max mem: 3158\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.9779 (1.9736)  acc1: 28.9062 (29.4700)  acc5: 82.8125 (82.7400)  time: 0.5184  data: 0.0313  max mem: 3158\n",
            "Test: Total time: 0:00:22 (0.5503 s / it)\n",
            "* Acc@1 29.470 Acc@5 82.740 loss 1.974\n",
            "Accuracy of the network on the 625 train images: 28.5%\n",
            "Accuracy of the network on the 40 test images: 29.5%\n",
            "Epoch: [2]  [  0/625]  eta: 0:02:02  loss: 1.8590 (1.8590)  time: 0.1952  data: 0.0975  max mem: 3158\n",
            "Epoch: [2]  [100/625]  eta: 0:00:54  loss: 1.9295 (1.9482)  time: 0.1014  data: 0.0037  max mem: 3158\n",
            "Epoch: [2]  [200/625]  eta: 0:00:43  loss: 1.8698 (1.9215)  time: 0.1011  data: 0.0037  max mem: 3158\n",
            "Epoch: [2]  [300/625]  eta: 0:00:33  loss: 1.7626 (1.9003)  time: 0.1018  data: 0.0042  max mem: 3158\n",
            "Epoch: [2]  [400/625]  eta: 0:00:22  loss: 1.8171 (1.8945)  time: 0.1013  data: 0.0037  max mem: 3158\n",
            "Epoch: [2]  [500/625]  eta: 0:00:12  loss: 1.7713 (1.8887)  time: 0.1017  data: 0.0037  max mem: 3158\n",
            "Epoch: [2]  [600/625]  eta: 0:00:02  loss: 1.6830 (1.8795)  time: 0.1016  data: 0.0037  max mem: 3158\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 1.8463 (1.8773)  time: 0.1017  data: 0.0037  max mem: 3158\n",
            "Epoch: [2] Total time: 0:01:03 (0.1019 s / it)\n",
            "Averaged stats: loss: 1.8463 (1.8773)\n",
            "Test:  [  0/625]  eta: 0:01:17  loss: 1.6342 (1.6342)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 0.1246  data: 0.0991  max mem: 3158\n",
            "Test:  [ 20/625]  eta: 0:00:25  loss: 1.7452 (1.7304)  acc1: 31.2500 (30.9524)  acc5: 93.7500 (89.2857)  time: 0.0378  data: 0.0119  max mem: 3158\n",
            "Test:  [ 40/625]  eta: 0:00:23  loss: 1.6966 (1.7415)  acc1: 37.5000 (33.9939)  acc5: 87.5000 (89.0244)  time: 0.0369  data: 0.0100  max mem: 3158\n",
            "Test:  [ 60/625]  eta: 0:00:20  loss: 1.7382 (1.7824)  acc1: 31.2500 (33.6066)  acc5: 81.2500 (86.8852)  time: 0.0299  data: 0.0033  max mem: 3158\n",
            "Test:  [ 80/625]  eta: 0:00:18  loss: 1.8334 (1.7866)  acc1: 31.2500 (34.1049)  acc5: 87.5000 (86.4198)  time: 0.0304  data: 0.0033  max mem: 3158\n",
            "Test:  [100/625]  eta: 0:00:17  loss: 1.8184 (1.7960)  acc1: 31.2500 (33.9109)  acc5: 81.2500 (85.4579)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [120/625]  eta: 0:00:16  loss: 1.7507 (1.7972)  acc1: 31.2500 (33.7810)  acc5: 81.2500 (85.4339)  time: 0.0303  data: 0.0033  max mem: 3158\n",
            "Test:  [140/625]  eta: 0:00:15  loss: 1.8730 (1.8069)  acc1: 25.0000 (32.8457)  acc5: 81.2500 (84.7961)  time: 0.0300  data: 0.0034  max mem: 3158\n",
            "Test:  [160/625]  eta: 0:00:15  loss: 1.7584 (1.8036)  acc1: 31.2500 (33.1522)  acc5: 87.5000 (84.7050)  time: 0.0300  data: 0.0034  max mem: 3158\n",
            "Test:  [180/625]  eta: 0:00:14  loss: 1.8024 (1.8033)  acc1: 31.2500 (33.2873)  acc5: 87.5000 (84.7721)  time: 0.0304  data: 0.0034  max mem: 3158\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 1.7663 (1.8037)  acc1: 31.2500 (33.0535)  acc5: 87.5000 (85.0435)  time: 0.0302  data: 0.0033  max mem: 3158\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 1.6810 (1.8027)  acc1: 31.2500 (32.9186)  acc5: 87.5000 (85.2658)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [240/625]  eta: 0:00:12  loss: 1.7375 (1.7957)  acc1: 31.2500 (33.1950)  acc5: 87.5000 (85.2956)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 1.7648 (1.7958)  acc1: 37.5000 (33.1418)  acc5: 87.5000 (85.2730)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 1.8142 (1.7970)  acc1: 31.2500 (33.2740)  acc5: 81.2500 (85.2980)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [300/625]  eta: 0:00:10  loss: 1.7491 (1.7966)  acc1: 25.0000 (33.0565)  acc5: 87.5000 (85.3821)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 1.7929 (1.7975)  acc1: 31.2500 (32.8076)  acc5: 87.5000 (85.3777)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 1.8017 (1.7985)  acc1: 31.2500 (32.7713)  acc5: 87.5000 (85.3189)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 1.7507 (1.7959)  acc1: 31.2500 (32.7909)  acc5: 87.5000 (85.4051)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 1.7398 (1.7932)  acc1: 31.2500 (32.7592)  acc5: 87.5000 (85.4987)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [400/625]  eta: 0:00:07  loss: 1.7655 (1.7954)  acc1: 31.2500 (32.6683)  acc5: 87.5000 (85.4271)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 1.6884 (1.7918)  acc1: 31.2500 (32.6900)  acc5: 87.5000 (85.5255)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 1.7185 (1.7906)  acc1: 31.2500 (32.7948)  acc5: 87.5000 (85.5442)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 1.8394 (1.7925)  acc1: 31.2500 (32.7684)  acc5: 81.2500 (85.4935)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 1.8214 (1.7917)  acc1: 31.2500 (32.8482)  acc5: 87.5000 (85.5249)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 1.7845 (1.7903)  acc1: 37.5000 (32.8343)  acc5: 87.5000 (85.6163)  time: 0.0304  data: 0.0034  max mem: 3158\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 1.7330 (1.7898)  acc1: 31.2500 (32.8335)  acc5: 87.5000 (85.6766)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 1.8506 (1.7920)  acc1: 25.0000 (32.6594)  acc5: 87.5000 (85.6169)  time: 0.0303  data: 0.0036  max mem: 3158\n",
            "Test:  [560/625]  eta: 0:00:02  loss: 1.7910 (1.7911)  acc1: 31.2500 (32.6872)  acc5: 87.5000 (85.6729)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 1.7628 (1.7914)  acc1: 31.2500 (32.6485)  acc5: 87.5000 (85.7035)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.7385 (1.7904)  acc1: 37.5000 (32.7787)  acc5: 87.5000 (85.7113)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.6400 (1.7886)  acc1: 31.2500 (32.8402)  acc5: 87.5000 (85.7991)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.6400 (1.7875)  acc1: 37.5000 (32.8700)  acc5: 87.5000 (85.8300)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test: Total time: 0:00:19 (0.0310 s / it)\n",
            "* Acc@1 32.870 Acc@5 85.830 loss 1.787\n",
            "Test:  [ 0/40]  eta: 0:00:45  loss: 1.8211 (1.8211)  acc1: 33.5938 (33.5938)  acc5: 85.9375 (85.9375)  time: 1.1431  data: 0.6240  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.8068 (1.8136)  acc1: 33.2031 (32.8683)  acc5: 84.3750 (84.5982)  time: 0.5446  data: 0.0332  max mem: 3158\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.8215 (1.8094)  acc1: 32.0312 (33.0100)  acc5: 83.5938 (84.2600)  time: 0.5187  data: 0.0330  max mem: 3158\n",
            "Test: Total time: 0:00:21 (0.5475 s / it)\n",
            "* Acc@1 33.010 Acc@5 84.260 loss 1.809\n",
            "Accuracy of the network on the 625 train images: 32.9%\n",
            "Accuracy of the network on the 40 test images: 33.0%\n",
            "Epoch: [3]  [  0/625]  eta: 0:02:03  loss: 1.7889 (1.7889)  time: 0.1973  data: 0.0979  max mem: 3158\n",
            "Epoch: [3]  [100/625]  eta: 0:00:53  loss: 1.7396 (1.8045)  time: 0.1013  data: 0.0037  max mem: 3158\n",
            "Epoch: [3]  [200/625]  eta: 0:00:43  loss: 1.8407 (1.8171)  time: 0.1013  data: 0.0037  max mem: 3158\n",
            "Epoch: [3]  [300/625]  eta: 0:00:33  loss: 1.8169 (1.8098)  time: 0.1013  data: 0.0037  max mem: 3158\n",
            "Epoch: [3]  [400/625]  eta: 0:00:22  loss: 1.7530 (1.7959)  time: 0.1013  data: 0.0036  max mem: 3158\n",
            "Epoch: [3]  [500/625]  eta: 0:00:12  loss: 1.6879 (1.7922)  time: 0.1016  data: 0.0036  max mem: 3158\n",
            "Epoch: [3]  [600/625]  eta: 0:00:02  loss: 1.7519 (1.7846)  time: 0.1012  data: 0.0036  max mem: 3158\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 1.8363 (1.7867)  time: 0.1011  data: 0.0036  max mem: 3158\n",
            "Epoch: [3] Total time: 0:01:03 (0.1016 s / it)\n",
            "Averaged stats: loss: 1.8363 (1.7867)\n",
            "Test:  [  0/625]  eta: 0:01:16  loss: 1.8007 (1.8007)  acc1: 37.5000 (37.5000)  acc5: 87.5000 (87.5000)  time: 0.1218  data: 0.0966  max mem: 3158\n",
            "Test:  [ 20/625]  eta: 0:00:20  loss: 1.7795 (1.7835)  acc1: 31.2500 (34.5238)  acc5: 87.5000 (86.6071)  time: 0.0298  data: 0.0035  max mem: 3158\n",
            "Test:  [ 40/625]  eta: 0:00:18  loss: 1.6416 (1.7235)  acc1: 37.5000 (37.0427)  acc5: 87.5000 (88.1098)  time: 0.0304  data: 0.0034  max mem: 3158\n",
            "Test:  [ 60/625]  eta: 0:00:17  loss: 1.6469 (1.7129)  acc1: 37.5000 (36.4754)  acc5: 93.7500 (88.0123)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 1.6725 (1.7153)  acc1: 31.2500 (36.4198)  acc5: 87.5000 (87.9630)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 1.7883 (1.7335)  acc1: 31.2500 (35.6436)  acc5: 81.2500 (87.0050)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 1.7477 (1.7368)  acc1: 31.2500 (35.3822)  acc5: 87.5000 (86.8802)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [140/625]  eta: 0:00:14  loss: 1.6560 (1.7268)  acc1: 37.5000 (35.7713)  acc5: 87.5000 (87.0124)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 1.6987 (1.7250)  acc1: 37.5000 (35.6366)  acc5: 87.5000 (87.1894)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 1.6092 (1.7254)  acc1: 31.2500 (35.4282)  acc5: 87.5000 (87.2928)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 1.6270 (1.7203)  acc1: 31.2500 (35.4167)  acc5: 87.5000 (87.5311)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 1.7921 (1.7247)  acc1: 31.2500 (35.6052)  acc5: 87.5000 (87.2455)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 1.7086 (1.7237)  acc1: 31.2500 (35.5809)  acc5: 87.5000 (87.3963)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 1.6453 (1.7238)  acc1: 31.2500 (35.4646)  acc5: 93.7500 (87.5958)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 1.6412 (1.7213)  acc1: 31.2500 (35.3870)  acc5: 87.5000 (87.6557)  time: 0.0302  data: 0.0036  max mem: 3158\n",
            "Test:  [300/625]  eta: 0:00:09  loss: 1.6928 (1.7227)  acc1: 31.2500 (35.2990)  acc5: 87.5000 (87.7076)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 1.6291 (1.7209)  acc1: 37.5000 (35.4556)  acc5: 93.7500 (87.7726)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 1.8607 (1.7277)  acc1: 31.2500 (35.2456)  acc5: 87.5000 (87.7383)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 1.6987 (1.7277)  acc1: 37.5000 (35.2493)  acc5: 87.5000 (87.7770)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 1.6637 (1.7293)  acc1: 31.2500 (35.1870)  acc5: 87.5000 (87.7789)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 1.6802 (1.7272)  acc1: 37.5000 (35.3647)  acc5: 87.5000 (87.8429)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 1.6548 (1.7253)  acc1: 31.2500 (35.2732)  acc5: 93.7500 (87.8563)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 1.7063 (1.7261)  acc1: 31.2500 (35.0907)  acc5: 87.5000 (87.8968)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 1.6196 (1.7235)  acc1: 37.5000 (35.1003)  acc5: 87.5000 (87.9474)  time: 0.0300  data: 0.0034  max mem: 3158\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 1.6516 (1.7222)  acc1: 31.2500 (34.9922)  acc5: 93.7500 (88.0847)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 1.7339 (1.7246)  acc1: 31.2500 (34.9052)  acc5: 87.5000 (87.9616)  time: 0.0306  data: 0.0040  max mem: 3158\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 1.6900 (1.7247)  acc1: 31.2500 (34.8129)  acc5: 87.5000 (87.9918)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 1.7515 (1.7241)  acc1: 37.5000 (34.9238)  acc5: 87.5000 (87.9852)  time: 0.0300  data: 0.0034  max mem: 3158\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 1.6811 (1.7217)  acc1: 37.5000 (35.0156)  acc5: 81.2500 (87.9011)  time: 0.0304  data: 0.0034  max mem: 3158\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 1.7361 (1.7230)  acc1: 31.2500 (34.9720)  acc5: 87.5000 (87.8335)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.6700 (1.7240)  acc1: 37.5000 (35.0354)  acc5: 87.5000 (87.7496)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.7232 (1.7242)  acc1: 31.2500 (35.0342)  acc5: 87.5000 (87.7114)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.7218 (1.7241)  acc1: 31.2500 (35.0300)  acc5: 87.5000 (87.7100)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test: Total time: 0:00:19 (0.0305 s / it)\n",
            "* Acc@1 35.030 Acc@5 87.710 loss 1.724\n",
            "Test:  [ 0/40]  eta: 0:00:46  loss: 1.7394 (1.7394)  acc1: 37.5000 (37.5000)  acc5: 87.1094 (87.1094)  time: 1.1598  data: 0.6369  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.7993 (1.7844)  acc1: 31.6406 (32.5521)  acc5: 86.7188 (87.0164)  time: 0.5415  data: 0.0312  max mem: 3158\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.8047 (1.7828)  acc1: 33.2031 (32.7800)  acc5: 86.7188 (86.7600)  time: 0.5188  data: 0.0312  max mem: 3158\n",
            "Test: Total time: 0:00:21 (0.5471 s / it)\n",
            "* Acc@1 32.780 Acc@5 86.760 loss 1.783\n",
            "Accuracy of the network on the 625 train images: 35.0%\n",
            "Accuracy of the network on the 40 test images: 32.8%\n",
            "Epoch: [4]  [  0/625]  eta: 0:02:03  loss: 1.9433 (1.9433)  time: 0.1975  data: 0.0981  max mem: 3158\n",
            "Epoch: [4]  [100/625]  eta: 0:00:53  loss: 1.6443 (1.7186)  time: 0.1011  data: 0.0036  max mem: 3158\n",
            "Epoch: [4]  [200/625]  eta: 0:00:43  loss: 1.7081 (1.7432)  time: 0.1013  data: 0.0037  max mem: 3158\n",
            "Epoch: [4]  [300/625]  eta: 0:00:32  loss: 1.7328 (1.7427)  time: 0.1012  data: 0.0037  max mem: 3158\n",
            "Epoch: [4]  [400/625]  eta: 0:00:22  loss: 1.7343 (1.7406)  time: 0.1015  data: 0.0037  max mem: 3158\n",
            "Epoch: [4]  [500/625]  eta: 0:00:12  loss: 1.6731 (1.7323)  time: 0.1010  data: 0.0036  max mem: 3158\n",
            "Epoch: [4]  [600/625]  eta: 0:00:02  loss: 1.6184 (1.7292)  time: 0.1011  data: 0.0037  max mem: 3158\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 1.5991 (1.7273)  time: 0.1010  data: 0.0036  max mem: 3158\n",
            "Epoch: [4] Total time: 0:01:03 (0.1014 s / it)\n",
            "Averaged stats: loss: 1.5991 (1.7273)\n",
            "Test:  [  0/625]  eta: 0:01:15  loss: 1.6437 (1.6437)  acc1: 31.2500 (31.2500)  acc5: 93.7500 (93.7500)  time: 0.1214  data: 0.0960  max mem: 3158\n",
            "Test:  [ 20/625]  eta: 0:00:20  loss: 1.6956 (1.6940)  acc1: 37.5000 (38.6905)  acc5: 87.5000 (87.5000)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [ 40/625]  eta: 0:00:18  loss: 1.6708 (1.7074)  acc1: 31.2500 (35.2134)  acc5: 87.5000 (88.8720)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [ 60/625]  eta: 0:00:17  loss: 1.6580 (1.7095)  acc1: 31.2500 (35.1434)  acc5: 93.7500 (88.9344)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 1.7037 (1.7096)  acc1: 37.5000 (35.9568)  acc5: 87.5000 (88.7346)  time: 0.0305  data: 0.0038  max mem: 3158\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 1.6771 (1.6991)  acc1: 37.5000 (36.3861)  acc5: 87.5000 (88.6757)  time: 0.0302  data: 0.0036  max mem: 3158\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 1.7328 (1.7004)  acc1: 31.2500 (36.6219)  acc5: 87.5000 (88.5847)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [140/625]  eta: 0:00:14  loss: 1.6981 (1.6996)  acc1: 43.7500 (37.1454)  acc5: 87.5000 (88.3422)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 1.6112 (1.6990)  acc1: 37.5000 (37.1506)  acc5: 93.7500 (88.5093)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 1.5903 (1.6916)  acc1: 37.5000 (37.2238)  acc5: 87.5000 (88.6395)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 1.7351 (1.6945)  acc1: 25.0000 (36.9714)  acc5: 93.7500 (88.6816)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 1.7012 (1.6970)  acc1: 37.5000 (36.7930)  acc5: 87.5000 (88.5747)  time: 0.0308  data: 0.0039  max mem: 3158\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 1.7016 (1.7027)  acc1: 31.2500 (36.3589)  acc5: 87.5000 (88.4077)  time: 0.0301  data: 0.0036  max mem: 3158\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 1.6532 (1.7012)  acc1: 37.5000 (36.3266)  acc5: 87.5000 (88.4100)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 1.7661 (1.7059)  acc1: 31.2500 (36.0765)  acc5: 87.5000 (88.2785)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [300/625]  eta: 0:00:09  loss: 1.7041 (1.7070)  acc1: 31.2500 (35.9427)  acc5: 87.5000 (88.2890)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 1.7682 (1.7102)  acc1: 31.2500 (35.6114)  acc5: 87.5000 (88.2009)  time: 0.0302  data: 0.0036  max mem: 3158\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 1.6455 (1.7061)  acc1: 37.5000 (35.7771)  acc5: 87.5000 (88.1782)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 1.7268 (1.7068)  acc1: 31.2500 (35.7687)  acc5: 87.5000 (88.1060)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 1.6697 (1.7068)  acc1: 31.2500 (35.7776)  acc5: 87.5000 (88.1726)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 1.7283 (1.7064)  acc1: 37.5000 (35.8479)  acc5: 87.5000 (88.2014)  time: 0.0303  data: 0.0036  max mem: 3158\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 1.6492 (1.7038)  acc1: 37.5000 (35.9412)  acc5: 87.5000 (88.1977)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 1.6777 (1.7039)  acc1: 31.2500 (36.0261)  acc5: 87.5000 (88.1378)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 1.6767 (1.7056)  acc1: 37.5000 (36.0900)  acc5: 87.5000 (88.0694)  time: 0.0303  data: 0.0036  max mem: 3158\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 1.7068 (1.7072)  acc1: 31.2500 (36.0057)  acc5: 93.7500 (88.1107)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 1.8219 (1.7094)  acc1: 37.5000 (36.0778)  acc5: 87.5000 (88.0489)  time: 0.0302  data: 0.0036  max mem: 3158\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 1.8138 (1.7129)  acc1: 37.5000 (35.9525)  acc5: 87.5000 (87.8839)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 1.6782 (1.7106)  acc1: 37.5000 (36.1137)  acc5: 93.7500 (87.9159)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 1.6748 (1.7101)  acc1: 37.5000 (36.1297)  acc5: 93.7500 (87.9345)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 1.6781 (1.7085)  acc1: 31.2500 (36.1338)  acc5: 87.5000 (87.9410)  time: 0.0300  data: 0.0035  max mem: 3158\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.6734 (1.7067)  acc1: 43.7500 (36.2937)  acc5: 87.5000 (87.9888)  time: 0.0304  data: 0.0038  max mem: 3158\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.6648 (1.7060)  acc1: 37.5000 (36.2419)  acc5: 87.5000 (88.0133)  time: 0.0303  data: 0.0036  max mem: 3158\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.7294 (1.7066)  acc1: 31.2500 (36.2400)  acc5: 87.5000 (88.0200)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test: Total time: 0:00:19 (0.0305 s / it)\n",
            "* Acc@1 36.240 Acc@5 88.020 loss 1.707\n",
            "Test:  [ 0/40]  eta: 0:00:46  loss: 1.7499 (1.7499)  acc1: 35.5469 (35.5469)  acc5: 85.5469 (85.5469)  time: 1.1658  data: 0.6471  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.8256 (1.8229)  acc1: 33.2031 (33.0357)  acc5: 86.3281 (86.1421)  time: 0.5423  data: 0.0311  max mem: 3158\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.8196 (1.8128)  acc1: 33.2031 (33.1100)  acc5: 85.9375 (85.8800)  time: 0.5187  data: 0.0311  max mem: 3158\n",
            "Test: Total time: 0:00:21 (0.5476 s / it)\n",
            "* Acc@1 33.110 Acc@5 85.880 loss 1.813\n",
            "Accuracy of the network on the 625 train images: 36.2%\n",
            "Accuracy of the network on the 40 test images: 33.1%\n",
            "Epoch: [5]  [  0/625]  eta: 0:02:03  loss: 2.0702 (2.0702)  time: 0.1983  data: 0.0999  max mem: 3158\n",
            "Epoch: [5]  [100/625]  eta: 0:00:53  loss: 1.6865 (1.6995)  time: 0.1007  data: 0.0036  max mem: 3158\n",
            "Epoch: [5]  [200/625]  eta: 0:00:43  loss: 1.7347 (1.6952)  time: 0.1013  data: 0.0037  max mem: 3158\n",
            "Epoch: [5]  [300/625]  eta: 0:00:32  loss: 1.6519 (1.6882)  time: 0.1009  data: 0.0036  max mem: 3158\n",
            "Epoch: [5]  [400/625]  eta: 0:00:22  loss: 1.6273 (1.6933)  time: 0.1011  data: 0.0037  max mem: 3158\n",
            "Epoch: [5]  [500/625]  eta: 0:00:12  loss: 1.6174 (1.6911)  time: 0.1014  data: 0.0038  max mem: 3158\n",
            "Epoch: [5]  [600/625]  eta: 0:00:02  loss: 1.6960 (1.6901)  time: 0.1019  data: 0.0042  max mem: 3158\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 1.6646 (1.6901)  time: 0.1014  data: 0.0038  max mem: 3158\n",
            "Epoch: [5] Total time: 0:01:03 (0.1015 s / it)\n",
            "Averaged stats: loss: 1.6646 (1.6901)\n",
            "Test:  [  0/625]  eta: 0:01:16  loss: 1.8590 (1.8590)  acc1: 25.0000 (25.0000)  acc5: 75.0000 (75.0000)  time: 0.1231  data: 0.0976  max mem: 3158\n",
            "Test:  [ 20/625]  eta: 0:00:21  loss: 1.5313 (1.6840)  acc1: 37.5000 (36.9048)  acc5: 87.5000 (87.2024)  time: 0.0303  data: 0.0038  max mem: 3158\n",
            "Test:  [ 40/625]  eta: 0:00:19  loss: 1.5688 (1.6319)  acc1: 43.7500 (38.8720)  acc5: 93.7500 (89.0244)  time: 0.0305  data: 0.0036  max mem: 3158\n",
            "Test:  [ 60/625]  eta: 0:00:17  loss: 1.5309 (1.6198)  acc1: 37.5000 (40.5738)  acc5: 87.5000 (89.0369)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 1.6358 (1.6183)  acc1: 37.5000 (40.9722)  acc5: 87.5000 (89.3519)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 1.5175 (1.6103)  acc1: 50.0000 (41.8317)  acc5: 93.7500 (89.4183)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 1.5971 (1.6190)  acc1: 37.5000 (41.5289)  acc5: 87.5000 (89.2045)  time: 0.0302  data: 0.0036  max mem: 3158\n",
            "Test:  [140/625]  eta: 0:00:15  loss: 1.6703 (1.6335)  acc1: 37.5000 (41.0018)  acc5: 87.5000 (88.8298)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 1.5899 (1.6327)  acc1: 43.7500 (40.7997)  acc5: 87.5000 (88.7034)  time: 0.0303  data: 0.0036  max mem: 3158\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 1.6266 (1.6317)  acc1: 37.5000 (40.6423)  acc5: 87.5000 (88.9503)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 1.6311 (1.6328)  acc1: 31.2500 (40.3607)  acc5: 87.5000 (88.9925)  time: 0.0305  data: 0.0037  max mem: 3158\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 1.6778 (1.6396)  acc1: 37.5000 (40.2715)  acc5: 87.5000 (88.7726)  time: 0.0305  data: 0.0039  max mem: 3158\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 1.5324 (1.6355)  acc1: 37.5000 (40.4824)  acc5: 87.5000 (88.7707)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 1.4334 (1.6298)  acc1: 37.5000 (40.3975)  acc5: 93.7500 (88.8410)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 1.5274 (1.6279)  acc1: 37.5000 (40.2358)  acc5: 93.7500 (88.9902)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [300/625]  eta: 0:00:09  loss: 1.7906 (1.6371)  acc1: 31.2500 (39.8879)  acc5: 87.5000 (88.7874)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 1.6038 (1.6361)  acc1: 37.5000 (39.6807)  acc5: 93.7500 (88.9213)  time: 0.0301  data: 0.0035  max mem: 3158\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 1.6481 (1.6369)  acc1: 37.5000 (39.7727)  acc5: 87.5000 (88.9296)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 1.5674 (1.6372)  acc1: 37.5000 (39.5776)  acc5: 87.5000 (89.0235)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 1.5639 (1.6320)  acc1: 43.7500 (39.8130)  acc5: 93.7500 (89.1568)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 1.6339 (1.6341)  acc1: 37.5000 (39.7600)  acc5: 87.5000 (89.0742)  time: 0.0301  data: 0.0036  max mem: 3158\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 1.6236 (1.6339)  acc1: 37.5000 (39.7268)  acc5: 93.7500 (89.1182)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 1.6927 (1.6371)  acc1: 43.7500 (39.7534)  acc5: 87.5000 (89.1015)  time: 0.0304  data: 0.0035  max mem: 3158\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 1.6164 (1.6367)  acc1: 37.5000 (39.6421)  acc5: 93.7500 (89.1676)  time: 0.0302  data: 0.0035  max mem: 3158\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 1.5533 (1.6357)  acc1: 37.5000 (39.6050)  acc5: 93.7500 (89.2801)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 1.5513 (1.6338)  acc1: 37.5000 (39.6707)  acc5: 87.5000 (89.2216)  time: 0.0300  data: 0.0034  max mem: 3158\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 1.6519 (1.6346)  acc1: 37.5000 (39.6353)  acc5: 87.5000 (89.2035)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 1.5313 (1.6335)  acc1: 37.5000 (39.6372)  acc5: 87.5000 (89.1751)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 1.7037 (1.6353)  acc1: 25.0000 (39.3605)  acc5: 87.5000 (89.1823)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 1.5577 (1.6337)  acc1: 37.5000 (39.4040)  acc5: 93.7500 (89.2319)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.5474 (1.6315)  acc1: 37.5000 (39.5279)  acc5: 93.7500 (89.3407)  time: 0.0305  data: 0.0037  max mem: 3158\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.5558 (1.6302)  acc1: 37.5000 (39.6739)  acc5: 87.5000 (89.3619)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.5558 (1.6299)  acc1: 37.5000 (39.6900)  acc5: 87.5000 (89.3300)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test: Total time: 0:00:19 (0.0306 s / it)\n",
            "* Acc@1 39.690 Acc@5 89.330 loss 1.630\n",
            "Test:  [ 0/40]  eta: 0:00:46  loss: 1.8480 (1.8480)  acc1: 31.6406 (31.6406)  acc5: 84.7656 (84.7656)  time: 1.1539  data: 0.6326  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.7542 (1.7542)  acc1: 34.3750 (34.3192)  acc5: 87.8906 (87.7604)  time: 0.5429  data: 0.0310  max mem: 3158\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.7649 (1.7464)  acc1: 33.9844 (34.2300)  acc5: 87.1094 (87.5000)  time: 0.5190  data: 0.0310  max mem: 3158\n",
            "Test: Total time: 0:00:21 (0.5479 s / it)\n",
            "* Acc@1 34.230 Acc@5 87.500 loss 1.746\n",
            "Accuracy of the network on the 625 train images: 39.7%\n",
            "Accuracy of the network on the 40 test images: 34.2%\n",
            "Test:  [ 0/40]  eta: 0:00:46  loss: 1.8480 (1.8480)  acc1: 31.6406 (31.6406)  acc5: 84.7656 (84.7656)  time: 1.1603  data: 0.6500  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.7542 (1.7542)  acc1: 34.3750 (34.3192)  acc5: 87.8906 (87.7604)  time: 0.5444  data: 0.0315  max mem: 3158\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.7649 (1.7464)  acc1: 33.9844 (34.2300)  acc5: 87.1094 (87.5000)  time: 0.5207  data: 0.0316  max mem: 3158\n",
            "Test: Total time: 0:00:21 (0.5497 s / it)\n",
            "* Acc@1 34.230 Acc@5 87.500 loss 1.746\n",
            "Accuracy of the network on the 40 test images: 34.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate througput\n",
        "start_time = time.time()\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "end_time = time.time()\n",
        "num_samples = len(cifar10_test_loader.dataset)\n",
        "throughput = num_samples / (end_time - start_time)\n",
        "print(\"Throughput: {}\".format(throughput))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwEmY19DrnTE",
        "outputId": "7932de38-0fa7-46b8-fb0f-059dd553453b"
      },
      "id": "QwEmY19DrnTE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:00:46  loss: 1.8480 (1.8480)  acc1: 31.6406 (31.6406)  acc5: 84.7656 (84.7656)  time: 1.1592  data: 0.6386  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.7542 (1.7542)  acc1: 34.3750 (34.3192)  acc5: 87.8906 (87.7604)  time: 0.5548  data: 0.0311  max mem: 3158\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.7649 (1.7464)  acc1: 33.9844 (34.2300)  acc5: 87.1094 (87.5000)  time: 0.5336  data: 0.0311  max mem: 3158\n",
            "Test: Total time: 0:00:22 (0.5605 s / it)\n",
            "* Acc@1 34.230 Acc@5 87.500 loss 1.746\n",
            "Throughput: 445.9432419403781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xoHlSMpWyzxT"
      },
      "id": "xoHlSMpWyzxT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2"
      ],
      "metadata": {
        "id": "Mb4ZcDyMr1tZ"
      },
      "id": "Mb4ZcDyMr1tZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234c6ce8",
      "metadata": {
        "id": "234c6ce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1784625-68bb-444e-a6a6-4edec51d3ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_base_patch16_224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth\" to /root/.cache/torch/hub/checkpoints/deit_base_patch16_224-b5f2ef4d.pth\n",
            "100%|██████████| 330M/330M [00:01<00:00, 228MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "number of params: 85806346\n"
          ]
        }
      ],
      "source": [
        "MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "CHECKPOINT_PATH = './checkpoint'\n",
        "MODEL_NAME = 'vit_base_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "shots = 1000\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "cifar10_training_loader = get_training_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=2,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    shots=shots\n",
        ")\n",
        "\n",
        "assert (shots*num_classes == len(cifar10_training_loader.dataset))\n",
        "\n",
        "cifar10_test_loader = get_test_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=4,\n",
        "    batch_size=256,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f51e2794",
      "metadata": {
        "id": "f51e2794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958cad77-2001-4749-d6b2-9e5870ab16ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:02:27  loss: 2.3259 (2.3259)  time: 0.2363  data: 0.1196  max mem: 3158\n",
            "Epoch: [1]  [100/625]  eta: 0:00:54  loss: 2.1496 (2.2712)  time: 0.1022  data: 0.0034  max mem: 3158\n",
            "Epoch: [1]  [200/625]  eta: 0:00:43  loss: 2.0386 (2.1677)  time: 0.1024  data: 0.0035  max mem: 3158\n",
            "Epoch: [1]  [300/625]  eta: 0:00:33  loss: 1.8758 (2.1013)  time: 0.1027  data: 0.0037  max mem: 3158\n",
            "Epoch: [1]  [400/625]  eta: 0:00:23  loss: 1.7478 (2.0338)  time: 0.1024  data: 0.0037  max mem: 3158\n",
            "Epoch: [1]  [500/625]  eta: 0:00:12  loss: 1.5791 (1.9594)  time: 0.1022  data: 0.0038  max mem: 3158\n",
            "Epoch: [1]  [600/625]  eta: 0:00:02  loss: 1.2156 (1.8595)  time: 0.1030  data: 0.0042  max mem: 3158\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 1.4263 (1.8421)  time: 0.1026  data: 0.0041  max mem: 3158\n",
            "Epoch: [1] Total time: 0:01:04 (0.1027 s / it)\n",
            "Averaged stats: loss: 1.4263 (1.8421)\n",
            "Test:  [  0/625]  eta: 0:01:23  loss: 0.9358 (0.9358)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.1333  data: 0.1080  max mem: 3158\n",
            "Test:  [ 20/625]  eta: 0:00:21  loss: 1.1924 (1.2072)  acc1: 56.2500 (57.4405)  acc5: 93.7500 (94.3452)  time: 0.0299  data: 0.0035  max mem: 3158\n",
            "Test:  [ 40/625]  eta: 0:00:19  loss: 1.2441 (1.2178)  acc1: 56.2500 (56.5549)  acc5: 93.7500 (93.7500)  time: 0.0304  data: 0.0034  max mem: 3158\n",
            "Test:  [ 60/625]  eta: 0:00:17  loss: 1.1670 (1.2098)  acc1: 62.5000 (57.8893)  acc5: 93.7500 (94.4672)  time: 0.0300  data: 0.0034  max mem: 3158\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 1.1054 (1.1971)  acc1: 62.5000 (57.6389)  acc5: 100.0000 (94.9846)  time: 0.0304  data: 0.0033  max mem: 3158\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 1.1139 (1.1918)  acc1: 56.2500 (57.8589)  acc5: 100.0000 (95.3589)  time: 0.0302  data: 0.0034  max mem: 3158\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 1.1765 (1.1912)  acc1: 56.2500 (57.3864)  acc5: 93.7500 (95.4029)  time: 0.0300  data: 0.0033  max mem: 3158\n",
            "Test:  [140/625]  eta: 0:00:14  loss: 1.1375 (1.1851)  acc1: 56.2500 (57.4468)  acc5: 100.0000 (95.5674)  time: 0.0300  data: 0.0033  max mem: 3158\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 1.2835 (1.1961)  acc1: 50.0000 (56.8323)  acc5: 93.7500 (95.3028)  time: 0.0304  data: 0.0034  max mem: 3158\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 1.1920 (1.1958)  acc1: 56.2500 (56.8715)  acc5: 93.7500 (95.2348)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 1.1195 (1.1939)  acc1: 62.5000 (57.2450)  acc5: 100.0000 (95.3358)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 1.1902 (1.1939)  acc1: 56.2500 (57.3529)  acc5: 100.0000 (95.3903)  time: 0.0307  data: 0.0039  max mem: 3158\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 1.1656 (1.1947)  acc1: 56.2500 (57.3651)  acc5: 93.7500 (95.3579)  time: 0.0303  data: 0.0037  max mem: 3158\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 1.1956 (1.1968)  acc1: 50.0000 (57.2797)  acc5: 100.0000 (95.4502)  time: 0.0305  data: 0.0037  max mem: 3158\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 1.1848 (1.1963)  acc1: 56.2500 (57.2954)  acc5: 93.7500 (95.5071)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [300/625]  eta: 0:00:09  loss: 1.1084 (1.1941)  acc1: 56.2500 (57.5581)  acc5: 100.0000 (95.5565)  time: 0.0304  data: 0.0036  max mem: 3158\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 1.1408 (1.1967)  acc1: 62.5000 (57.6129)  acc5: 100.0000 (95.5023)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 1.1187 (1.1946)  acc1: 62.5000 (57.6796)  acc5: 100.0000 (95.6195)  time: 0.0305  data: 0.0037  max mem: 3158\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 1.1501 (1.1923)  acc1: 62.5000 (57.8774)  acc5: 100.0000 (95.6371)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 1.2581 (1.1943)  acc1: 56.2500 (57.9068)  acc5: 93.7500 (95.6365)  time: 0.0305  data: 0.0037  max mem: 3158\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 1.1984 (1.1954)  acc1: 56.2500 (57.7618)  acc5: 93.7500 (95.6203)  time: 0.0306  data: 0.0038  max mem: 3158\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 1.1445 (1.1947)  acc1: 56.2500 (57.9276)  acc5: 100.0000 (95.6651)  time: 0.0306  data: 0.0039  max mem: 3158\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 1.1137 (1.1931)  acc1: 62.5000 (58.0357)  acc5: 93.7500 (95.6207)  time: 0.0306  data: 0.0039  max mem: 3158\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 1.2647 (1.1963)  acc1: 50.0000 (57.8091)  acc5: 93.7500 (95.6074)  time: 0.0304  data: 0.0038  max mem: 3158\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 1.1879 (1.1942)  acc1: 56.2500 (58.0172)  acc5: 100.0000 (95.6601)  time: 0.0305  data: 0.0037  max mem: 3158\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 1.0825 (1.1920)  acc1: 62.5000 (58.0963)  acc5: 100.0000 (95.6961)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 1.1387 (1.1894)  acc1: 56.2500 (58.1214)  acc5: 93.7500 (95.6814)  time: 0.0300  data: 0.0033  max mem: 3158\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 1.1974 (1.1906)  acc1: 50.0000 (57.9251)  acc5: 100.0000 (95.7140)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 1.0870 (1.1877)  acc1: 62.5000 (58.1439)  acc5: 93.7500 (95.7108)  time: 0.0301  data: 0.0034  max mem: 3158\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 1.0974 (1.1881)  acc1: 62.5000 (58.1433)  acc5: 100.0000 (95.7509)  time: 0.0303  data: 0.0035  max mem: 3158\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.1169 (1.1855)  acc1: 62.5000 (58.2051)  acc5: 100.0000 (95.7987)  time: 0.0304  data: 0.0037  max mem: 3158\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.1644 (1.1851)  acc1: 56.2500 (58.2931)  acc5: 93.7500 (95.7729)  time: 0.0304  data: 0.0034  max mem: 3158\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.1545 (1.1842)  acc1: 62.5000 (58.3800)  acc5: 93.7500 (95.7800)  time: 0.0303  data: 0.0034  max mem: 3158\n",
            "Test: Total time: 0:00:19 (0.0306 s / it)\n",
            "* Acc@1 58.380 Acc@5 95.780 loss 1.184\n",
            "Test:  [ 0/40]  eta: 0:00:50  loss: 1.2872 (1.2872)  acc1: 56.2500 (56.2500)  acc5: 96.0938 (96.0938)  time: 1.2625  data: 0.7446  max mem: 3158\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 1.2015 (1.2134)  acc1: 57.8125 (57.9613)  acc5: 95.7031 (95.7589)  time: 0.5457  data: 0.0313  max mem: 3368\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.2404 (1.2178)  acc1: 56.6406 (57.2000)  acc5: 95.3125 (95.6300)  time: 0.5225  data: 0.0314  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5536 s / it)\n",
            "* Acc@1 57.200 Acc@5 95.630 loss 1.218\n",
            "Accuracy of the network on the 625 train images: 58.4%\n",
            "Accuracy of the network on the 40 test images: 57.2%\n",
            "Epoch: [2]  [  0/625]  eta: 0:02:09  loss: 1.4344 (1.4344)  time: 0.2070  data: 0.1075  max mem: 3781\n",
            "Epoch: [2]  [100/625]  eta: 0:00:54  loss: 1.0979 (1.1842)  time: 0.1021  data: 0.0036  max mem: 3781\n",
            "Epoch: [2]  [200/625]  eta: 0:00:43  loss: 1.0028 (1.1242)  time: 0.1020  data: 0.0036  max mem: 3781\n",
            "Epoch: [2]  [300/625]  eta: 0:00:33  loss: 0.8803 (1.0772)  time: 0.1023  data: 0.0037  max mem: 3781\n",
            "Epoch: [2]  [400/625]  eta: 0:00:23  loss: 0.8679 (1.0331)  time: 0.1022  data: 0.0036  max mem: 3781\n",
            "Epoch: [2]  [500/625]  eta: 0:00:12  loss: 0.7075 (1.0019)  time: 0.1021  data: 0.0036  max mem: 3781\n",
            "Epoch: [2]  [600/625]  eta: 0:00:02  loss: 0.7530 (0.9674)  time: 0.1022  data: 0.0038  max mem: 3781\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 0.8272 (0.9635)  time: 0.1019  data: 0.0037  max mem: 3781\n",
            "Epoch: [2] Total time: 0:01:04 (0.1024 s / it)\n",
            "Averaged stats: loss: 0.8272 (0.9635)\n",
            "Test:  [  0/625]  eta: 0:01:24  loss: 0.3608 (0.3608)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.1352  data: 0.1100  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:21  loss: 0.6792 (0.6774)  acc1: 75.0000 (77.9762)  acc5: 100.0000 (98.8095)  time: 0.0300  data: 0.0034  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:19  loss: 0.6254 (0.6786)  acc1: 75.0000 (77.1341)  acc5: 100.0000 (98.7805)  time: 0.0304  data: 0.0034  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:18  loss: 0.6099 (0.6712)  acc1: 75.0000 (76.6393)  acc5: 100.0000 (98.8730)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 0.7168 (0.6911)  acc1: 75.0000 (75.7716)  acc5: 100.0000 (98.4568)  time: 0.0306  data: 0.0038  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 0.5566 (0.6729)  acc1: 81.2500 (76.6708)  acc5: 100.0000 (98.5149)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 0.6778 (0.6772)  acc1: 75.0000 (76.2913)  acc5: 100.0000 (98.5021)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:15  loss: 0.7107 (0.6765)  acc1: 75.0000 (76.3298)  acc5: 100.0000 (98.4486)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 0.6493 (0.6763)  acc1: 75.0000 (76.6304)  acc5: 100.0000 (98.3696)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 0.5343 (0.6673)  acc1: 75.0000 (77.1064)  acc5: 100.0000 (98.4116)  time: 0.0305  data: 0.0034  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 0.5928 (0.6666)  acc1: 75.0000 (77.0211)  acc5: 100.0000 (98.4764)  time: 0.0304  data: 0.0036  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 0.7006 (0.6680)  acc1: 75.0000 (76.8665)  acc5: 100.0000 (98.4729)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 0.7110 (0.6734)  acc1: 75.0000 (76.6857)  acc5: 100.0000 (98.4699)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 0.6600 (0.6758)  acc1: 75.0000 (76.7002)  acc5: 100.0000 (98.4195)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 0.6358 (0.6792)  acc1: 75.0000 (76.4902)  acc5: 100.0000 (98.4653)  time: 0.0304  data: 0.0034  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:09  loss: 0.6132 (0.6779)  acc1: 75.0000 (76.5158)  acc5: 100.0000 (98.4635)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 0.6974 (0.6783)  acc1: 81.2500 (76.5187)  acc5: 100.0000 (98.5008)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 0.6661 (0.6800)  acc1: 68.7500 (76.3380)  acc5: 100.0000 (98.5154)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 0.7631 (0.6867)  acc1: 68.7500 (76.1427)  acc5: 100.0000 (98.4938)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 0.6507 (0.6889)  acc1: 75.0000 (76.1319)  acc5: 100.0000 (98.4580)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 0.6438 (0.6883)  acc1: 81.2500 (76.2625)  acc5: 100.0000 (98.4726)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 0.6402 (0.6879)  acc1: 75.0000 (76.2025)  acc5: 100.0000 (98.5154)  time: 0.0301  data: 0.0034  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 0.5724 (0.6877)  acc1: 81.2500 (76.2046)  acc5: 100.0000 (98.5544)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 0.6578 (0.6855)  acc1: 81.2500 (76.4100)  acc5: 100.0000 (98.5629)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 0.5505 (0.6832)  acc1: 75.0000 (76.4163)  acc5: 100.0000 (98.5837)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 0.5894 (0.6826)  acc1: 81.2500 (76.5220)  acc5: 100.0000 (98.5903)  time: 0.0301  data: 0.0035  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 0.5694 (0.6794)  acc1: 75.0000 (76.6195)  acc5: 100.0000 (98.5605)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 0.6292 (0.6808)  acc1: 75.0000 (76.5018)  acc5: 100.0000 (98.5559)  time: 0.0305  data: 0.0036  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 0.5809 (0.6794)  acc1: 81.2500 (76.6488)  acc5: 100.0000 (98.5851)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 0.6112 (0.6780)  acc1: 81.2500 (76.6889)  acc5: 100.0000 (98.5800)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 0.7049 (0.6796)  acc1: 75.0000 (76.5807)  acc5: 100.0000 (98.5649)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 0.6817 (0.6812)  acc1: 75.0000 (76.5600)  acc5: 100.0000 (98.5709)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 0.6672 (0.6810)  acc1: 81.2500 (76.5900)  acc5: 100.0000 (98.5500)  time: 0.0303  data: 0.0036  max mem: 3781\n",
            "Test: Total time: 0:00:19 (0.0306 s / it)\n",
            "* Acc@1 76.590 Acc@5 98.550 loss 0.681\n",
            "Test:  [ 0/40]  eta: 0:00:50  loss: 0.8189 (0.8189)  acc1: 73.0469 (73.0469)  acc5: 98.8281 (98.8281)  time: 1.2595  data: 0.7475  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.7275 (0.7451)  acc1: 73.8281 (73.9397)  acc5: 98.0469 (98.1957)  time: 0.5446  data: 0.0315  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.7652 (0.7559)  acc1: 72.6562 (73.7000)  acc5: 98.4375 (98.2700)  time: 0.5216  data: 0.0319  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5527 s / it)\n",
            "* Acc@1 73.700 Acc@5 98.270 loss 0.756\n",
            "Accuracy of the network on the 625 train images: 76.6%\n",
            "Accuracy of the network on the 40 test images: 73.7%\n",
            "Epoch: [3]  [  0/625]  eta: 0:02:11  loss: 0.7796 (0.7796)  time: 0.2107  data: 0.1107  max mem: 3781\n",
            "Epoch: [3]  [100/625]  eta: 0:00:54  loss: 0.6136 (0.6588)  time: 0.1020  data: 0.0037  max mem: 3781\n",
            "Epoch: [3]  [200/625]  eta: 0:00:43  loss: 0.5753 (0.6429)  time: 0.1020  data: 0.0036  max mem: 3781\n",
            "Epoch: [3]  [300/625]  eta: 0:00:33  loss: 0.6366 (0.6590)  time: 0.1023  data: 0.0038  max mem: 3781\n",
            "Epoch: [3]  [400/625]  eta: 0:00:23  loss: 0.5900 (0.6585)  time: 0.1020  data: 0.0037  max mem: 3781\n",
            "Epoch: [3]  [500/625]  eta: 0:00:12  loss: 0.5611 (0.6415)  time: 0.1018  data: 0.0036  max mem: 3781\n",
            "Epoch: [3]  [600/625]  eta: 0:00:02  loss: 0.5028 (0.6332)  time: 0.1016  data: 0.0036  max mem: 3781\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.6796 (0.6380)  time: 0.1017  data: 0.0037  max mem: 3781\n",
            "Epoch: [3] Total time: 0:01:03 (0.1023 s / it)\n",
            "Averaged stats: loss: 0.6796 (0.6380)\n",
            "Test:  [  0/625]  eta: 0:01:24  loss: 0.6241 (0.6241)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 0.1355  data: 0.1102  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:21  loss: 0.5287 (0.6132)  acc1: 81.2500 (79.7619)  acc5: 100.0000 (98.5119)  time: 0.0303  data: 0.0036  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:19  loss: 0.4641 (0.5871)  acc1: 81.2500 (80.6402)  acc5: 100.0000 (99.2378)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:18  loss: 0.6549 (0.6041)  acc1: 75.0000 (78.8934)  acc5: 100.0000 (99.1803)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 0.5951 (0.6026)  acc1: 81.2500 (79.0895)  acc5: 100.0000 (99.3827)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 0.5645 (0.5978)  acc1: 81.2500 (79.3317)  acc5: 100.0000 (99.4431)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 0.5399 (0.5917)  acc1: 75.0000 (79.3905)  acc5: 100.0000 (99.2769)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:15  loss: 0.5201 (0.5850)  acc1: 81.2500 (79.6986)  acc5: 100.0000 (99.2908)  time: 0.0304  data: 0.0037  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 0.4627 (0.5774)  acc1: 81.2500 (80.0078)  acc5: 100.0000 (99.3012)  time: 0.0304  data: 0.0036  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 0.5696 (0.5818)  acc1: 81.2500 (79.9033)  acc5: 100.0000 (99.3094)  time: 0.0305  data: 0.0038  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 0.5528 (0.5784)  acc1: 87.5000 (80.1306)  acc5: 100.0000 (99.3159)  time: 0.0305  data: 0.0037  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 0.5445 (0.5796)  acc1: 81.2500 (79.9774)  acc5: 100.0000 (99.2647)  time: 0.0306  data: 0.0038  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 0.5815 (0.5831)  acc1: 75.0000 (79.8237)  acc5: 100.0000 (99.2220)  time: 0.0305  data: 0.0037  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 0.6155 (0.5863)  acc1: 75.0000 (79.7414)  acc5: 100.0000 (99.2337)  time: 0.0304  data: 0.0036  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 0.5383 (0.5871)  acc1: 75.0000 (79.7375)  acc5: 100.0000 (99.2215)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:09  loss: 0.6009 (0.5863)  acc1: 81.2500 (79.8796)  acc5: 100.0000 (99.1694)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 0.5194 (0.5846)  acc1: 87.5000 (80.0818)  acc5: 100.0000 (99.1433)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 0.5704 (0.5871)  acc1: 75.0000 (79.9670)  acc5: 100.0000 (99.1386)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 0.5792 (0.5868)  acc1: 81.2500 (79.9688)  acc5: 100.0000 (99.1343)  time: 0.0306  data: 0.0035  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 0.5089 (0.5837)  acc1: 81.2500 (80.0361)  acc5: 100.0000 (99.1470)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 0.5474 (0.5850)  acc1: 81.2500 (79.9408)  acc5: 100.0000 (99.1584)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 0.5581 (0.5869)  acc1: 75.0000 (79.8397)  acc5: 100.0000 (99.1686)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 0.4761 (0.5821)  acc1: 87.5000 (80.0454)  acc5: 100.0000 (99.1780)  time: 0.0301  data: 0.0034  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 0.5794 (0.5855)  acc1: 81.2500 (79.9892)  acc5: 100.0000 (99.1730)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 0.6003 (0.5865)  acc1: 75.0000 (79.9246)  acc5: 100.0000 (99.1814)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 0.6315 (0.5898)  acc1: 75.0000 (79.8902)  acc5: 100.0000 (99.1267)  time: 0.0303  data: 0.0036  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 0.4853 (0.5888)  acc1: 81.2500 (79.9424)  acc5: 100.0000 (99.1243)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 0.5599 (0.5892)  acc1: 81.2500 (79.9561)  acc5: 100.0000 (99.1335)  time: 0.0305  data: 0.0038  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 0.5864 (0.5900)  acc1: 75.0000 (79.8574)  acc5: 100.0000 (99.1533)  time: 0.0304  data: 0.0037  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 0.6403 (0.5921)  acc1: 75.0000 (79.7117)  acc5: 100.0000 (99.1609)  time: 0.0313  data: 0.0044  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 0.6529 (0.5948)  acc1: 75.0000 (79.5965)  acc5: 100.0000 (99.1577)  time: 0.0303  data: 0.0036  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 0.5278 (0.5945)  acc1: 81.2500 (79.6498)  acc5: 100.0000 (99.1647)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 0.5689 (0.5945)  acc1: 81.2500 (79.6600)  acc5: 100.0000 (99.1500)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test: Total time: 0:00:19 (0.0307 s / it)\n",
            "* Acc@1 79.660 Acc@5 99.150 loss 0.595\n",
            "Test:  [ 0/40]  eta: 0:00:50  loss: 0.7090 (0.7090)  acc1: 73.4375 (73.4375)  acc5: 98.4375 (98.4375)  time: 1.2605  data: 0.7479  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.6693 (0.6783)  acc1: 76.1719 (76.3951)  acc5: 98.8281 (98.6607)  time: 0.5453  data: 0.0312  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.6841 (0.6876)  acc1: 75.7812 (76.1500)  acc5: 98.8281 (98.6700)  time: 0.5235  data: 0.0314  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5537 s / it)\n",
            "* Acc@1 76.150 Acc@5 98.670 loss 0.688\n",
            "Accuracy of the network on the 625 train images: 79.7%\n",
            "Accuracy of the network on the 40 test images: 76.2%\n",
            "Epoch: [4]  [  0/625]  eta: 0:02:11  loss: 0.5564 (0.5564)  time: 0.2099  data: 0.1103  max mem: 3781\n",
            "Epoch: [4]  [100/625]  eta: 0:00:54  loss: 0.4245 (0.4680)  time: 0.1017  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [200/625]  eta: 0:00:43  loss: 0.4214 (0.4424)  time: 0.1016  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [300/625]  eta: 0:00:33  loss: 0.4113 (0.4584)  time: 0.1019  data: 0.0036  max mem: 3781\n",
            "Epoch: [4]  [400/625]  eta: 0:00:22  loss: 0.5446 (0.4652)  time: 0.1025  data: 0.0037  max mem: 3781\n",
            "Epoch: [4]  [500/625]  eta: 0:00:12  loss: 0.3888 (0.4689)  time: 0.1019  data: 0.0036  max mem: 3781\n",
            "Epoch: [4]  [600/625]  eta: 0:00:02  loss: 0.4862 (0.4649)  time: 0.1019  data: 0.0036  max mem: 3781\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.3096 (0.4641)  time: 0.1017  data: 0.0036  max mem: 3781\n",
            "Epoch: [4] Total time: 0:01:03 (0.1021 s / it)\n",
            "Averaged stats: loss: 0.3096 (0.4641)\n",
            "Test:  [  0/625]  eta: 0:01:23  loss: 0.3106 (0.3106)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.1333  data: 0.1080  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:21  loss: 0.4033 (0.4280)  acc1: 87.5000 (86.3095)  acc5: 100.0000 (100.0000)  time: 0.0302  data: 0.0036  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:19  loss: 0.5201 (0.4757)  acc1: 81.2500 (84.4512)  acc5: 100.0000 (99.6951)  time: 0.0304  data: 0.0033  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:18  loss: 0.5064 (0.4792)  acc1: 81.2500 (83.8115)  acc5: 100.0000 (99.7951)  time: 0.0302  data: 0.0033  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 0.3286 (0.4531)  acc1: 87.5000 (85.1080)  acc5: 100.0000 (99.8457)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 0.5255 (0.4615)  acc1: 87.5000 (84.9629)  acc5: 100.0000 (99.7525)  time: 0.0303  data: 0.0033  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 0.4169 (0.4667)  acc1: 81.2500 (84.7107)  acc5: 100.0000 (99.6384)  time: 0.0301  data: 0.0033  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:15  loss: 0.4091 (0.4675)  acc1: 81.2500 (84.5745)  acc5: 100.0000 (99.6897)  time: 0.0303  data: 0.0036  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 0.3744 (0.4667)  acc1: 87.5000 (84.4332)  acc5: 100.0000 (99.6894)  time: 0.0305  data: 0.0035  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 0.5451 (0.4770)  acc1: 81.2500 (84.1851)  acc5: 100.0000 (99.6202)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 0.4572 (0.4841)  acc1: 81.2500 (83.7376)  acc5: 100.0000 (99.6580)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 0.4027 (0.4842)  acc1: 81.2500 (83.7952)  acc5: 100.0000 (99.6324)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 0.3913 (0.4755)  acc1: 87.5000 (84.0768)  acc5: 100.0000 (99.6369)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 0.5445 (0.4762)  acc1: 81.2500 (84.0517)  acc5: 100.0000 (99.6648)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 0.4778 (0.4777)  acc1: 81.2500 (83.8078)  acc5: 100.0000 (99.6886)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:09  loss: 0.3877 (0.4762)  acc1: 81.2500 (83.6794)  acc5: 100.0000 (99.6885)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 0.3414 (0.4733)  acc1: 87.5000 (83.8006)  acc5: 100.0000 (99.6885)  time: 0.0305  data: 0.0036  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 0.4860 (0.4752)  acc1: 75.0000 (83.5777)  acc5: 100.0000 (99.6884)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 0.4729 (0.4758)  acc1: 87.5000 (83.5699)  acc5: 100.0000 (99.6884)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 0.4911 (0.4790)  acc1: 81.2500 (83.4482)  acc5: 100.0000 (99.6883)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 0.5626 (0.4833)  acc1: 81.2500 (83.2606)  acc5: 100.0000 (99.6727)  time: 0.0305  data: 0.0037  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 0.5139 (0.4855)  acc1: 81.2500 (83.1651)  acc5: 100.0000 (99.6882)  time: 0.0301  data: 0.0034  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 0.4459 (0.4846)  acc1: 87.5000 (83.2341)  acc5: 100.0000 (99.6882)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 0.4192 (0.4847)  acc1: 81.2500 (83.2430)  acc5: 100.0000 (99.6746)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 0.4693 (0.4862)  acc1: 81.2500 (83.1991)  acc5: 100.0000 (99.6881)  time: 0.0302  data: 0.0033  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 0.3546 (0.4833)  acc1: 81.2500 (83.3209)  acc5: 100.0000 (99.6756)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 0.5560 (0.4854)  acc1: 81.2500 (83.3013)  acc5: 100.0000 (99.6761)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 0.3763 (0.4820)  acc1: 87.5000 (83.4219)  acc5: 100.0000 (99.6881)  time: 0.0305  data: 0.0036  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 0.4373 (0.4803)  acc1: 81.2500 (83.3668)  acc5: 100.0000 (99.6992)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 0.4226 (0.4787)  acc1: 81.2500 (83.3584)  acc5: 100.0000 (99.6988)  time: 0.0302  data: 0.0033  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 0.4748 (0.4792)  acc1: 81.2500 (83.2675)  acc5: 100.0000 (99.6984)  time: 0.0305  data: 0.0034  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 0.4522 (0.4777)  acc1: 81.2500 (83.3535)  acc5: 100.0000 (99.7081)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 0.3121 (0.4762)  acc1: 87.5000 (83.4000)  acc5: 100.0000 (99.7100)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test: Total time: 0:00:19 (0.0306 s / it)\n",
            "* Acc@1 83.400 Acc@5 99.710 loss 0.476\n",
            "Test:  [ 0/40]  eta: 0:00:51  loss: 0.7307 (0.7307)  acc1: 74.2188 (74.2188)  acc5: 99.2188 (99.2188)  time: 1.2778  data: 0.7603  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.8129 (0.7949)  acc1: 75.0000 (74.9070)  acc5: 98.8281 (98.9211)  time: 0.5467  data: 0.0313  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.7654 (0.7830)  acc1: 74.6094 (75.0400)  acc5: 98.8281 (98.9100)  time: 0.5232  data: 0.0314  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5547 s / it)\n",
            "* Acc@1 75.040 Acc@5 98.910 loss 0.783\n",
            "Accuracy of the network on the 625 train images: 83.4%\n",
            "Accuracy of the network on the 40 test images: 75.0%\n",
            "Epoch: [5]  [  0/625]  eta: 0:02:09  loss: 0.4710 (0.4710)  time: 0.2071  data: 0.1083  max mem: 3781\n",
            "Epoch: [5]  [100/625]  eta: 0:00:53  loss: 0.2842 (0.3378)  time: 0.1016  data: 0.0036  max mem: 3781\n",
            "Epoch: [5]  [200/625]  eta: 0:00:43  loss: 0.3465 (0.3598)  time: 0.1015  data: 0.0035  max mem: 3781\n",
            "Epoch: [5]  [300/625]  eta: 0:00:33  loss: 0.3757 (0.3517)  time: 0.1018  data: 0.0037  max mem: 3781\n",
            "Epoch: [5]  [400/625]  eta: 0:00:22  loss: 0.4424 (0.3701)  time: 0.1017  data: 0.0036  max mem: 3781\n",
            "Epoch: [5]  [500/625]  eta: 0:00:12  loss: 0.3455 (0.3659)  time: 0.1015  data: 0.0035  max mem: 3781\n",
            "Epoch: [5]  [600/625]  eta: 0:00:02  loss: 0.2763 (0.3639)  time: 0.1017  data: 0.0036  max mem: 3781\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.3208 (0.3631)  time: 0.1015  data: 0.0036  max mem: 3781\n",
            "Epoch: [5] Total time: 0:01:03 (0.1020 s / it)\n",
            "Averaged stats: loss: 0.3208 (0.3631)\n",
            "Test:  [  0/625]  eta: 0:01:24  loss: 0.2035 (0.2035)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.1353  data: 0.1098  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:21  loss: 0.1091 (0.1420)  acc1: 93.7500 (93.4524)  acc5: 100.0000 (100.0000)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:19  loss: 0.1407 (0.1680)  acc1: 93.7500 (93.4451)  acc5: 100.0000 (100.0000)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:18  loss: 0.1976 (0.1727)  acc1: 93.7500 (93.5451)  acc5: 100.0000 (100.0000)  time: 0.0304  data: 0.0034  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:17  loss: 0.1652 (0.1794)  acc1: 93.7500 (93.1327)  acc5: 100.0000 (100.0000)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:16  loss: 0.1802 (0.1841)  acc1: 93.7500 (92.9455)  acc5: 100.0000 (100.0000)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:15  loss: 0.1450 (0.1842)  acc1: 93.7500 (93.1302)  acc5: 100.0000 (99.9483)  time: 0.0306  data: 0.0037  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:15  loss: 0.1967 (0.1878)  acc1: 93.7500 (93.1294)  acc5: 100.0000 (99.9113)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:14  loss: 0.1328 (0.1838)  acc1: 93.7500 (93.2842)  acc5: 100.0000 (99.9224)  time: 0.0307  data: 0.0038  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:13  loss: 0.1728 (0.1870)  acc1: 93.7500 (93.2320)  acc5: 100.0000 (99.9309)  time: 0.0309  data: 0.0040  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:13  loss: 0.1780 (0.1874)  acc1: 93.7500 (93.2525)  acc5: 100.0000 (99.9378)  time: 0.0306  data: 0.0038  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:12  loss: 0.1224 (0.1876)  acc1: 93.7500 (93.3824)  acc5: 100.0000 (99.9434)  time: 0.0305  data: 0.0035  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:11  loss: 0.1667 (0.1874)  acc1: 93.7500 (93.4647)  acc5: 100.0000 (99.9481)  time: 0.0306  data: 0.0037  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:11  loss: 0.1514 (0.1885)  acc1: 93.7500 (93.4866)  acc5: 100.0000 (99.9521)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:10  loss: 0.1590 (0.1882)  acc1: 93.7500 (93.4831)  acc5: 100.0000 (99.9555)  time: 0.0305  data: 0.0037  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:10  loss: 0.1373 (0.1860)  acc1: 93.7500 (93.5008)  acc5: 100.0000 (99.9585)  time: 0.0306  data: 0.0036  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:09  loss: 0.1394 (0.1865)  acc1: 93.7500 (93.5164)  acc5: 100.0000 (99.9611)  time: 0.0305  data: 0.0036  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:08  loss: 0.1880 (0.1871)  acc1: 93.7500 (93.4934)  acc5: 100.0000 (99.9633)  time: 0.0306  data: 0.0037  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:08  loss: 0.1629 (0.1891)  acc1: 93.7500 (93.4730)  acc5: 100.0000 (99.9481)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:07  loss: 0.1158 (0.1873)  acc1: 93.7500 (93.5203)  acc5: 100.0000 (99.9508)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:06  loss: 0.1205 (0.1864)  acc1: 93.7500 (93.5318)  acc5: 100.0000 (99.9532)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:06  loss: 0.1183 (0.1855)  acc1: 93.7500 (93.5719)  acc5: 100.0000 (99.9555)  time: 0.0304  data: 0.0034  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:05  loss: 0.1557 (0.1845)  acc1: 93.7500 (93.6508)  acc5: 100.0000 (99.9575)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:05  loss: 0.1203 (0.1852)  acc1: 93.7500 (93.6551)  acc5: 100.0000 (99.9593)  time: 0.0305  data: 0.0035  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:04  loss: 0.1698 (0.1863)  acc1: 93.7500 (93.6071)  acc5: 100.0000 (99.9610)  time: 0.0304  data: 0.0036  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:03  loss: 0.1055 (0.1840)  acc1: 93.7500 (93.7001)  acc5: 100.0000 (99.9626)  time: 0.0304  data: 0.0035  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:03  loss: 0.1382 (0.1847)  acc1: 93.7500 (93.6660)  acc5: 100.0000 (99.9640)  time: 0.0302  data: 0.0035  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:02  loss: 0.1288 (0.1845)  acc1: 93.7500 (93.5998)  acc5: 100.0000 (99.9653)  time: 0.0308  data: 0.0039  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 0.1396 (0.1839)  acc1: 93.7500 (93.6163)  acc5: 100.0000 (99.9666)  time: 0.0302  data: 0.0034  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:01  loss: 0.1754 (0.1841)  acc1: 93.7500 (93.6209)  acc5: 100.0000 (99.9677)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 0.1906 (0.1853)  acc1: 93.7500 (93.5836)  acc5: 100.0000 (99.9688)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 0.1292 (0.1842)  acc1: 93.7500 (93.6192)  acc5: 100.0000 (99.9698)  time: 0.0303  data: 0.0035  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 0.1201 (0.1838)  acc1: 93.7500 (93.6300)  acc5: 100.0000 (99.9700)  time: 0.0303  data: 0.0034  max mem: 3781\n",
            "Test: Total time: 0:00:19 (0.0307 s / it)\n",
            "* Acc@1 93.630 Acc@5 99.970 loss 0.184\n",
            "Test:  [ 0/40]  eta: 0:00:51  loss: 0.4256 (0.4256)  acc1: 86.7188 (86.7188)  acc5: 99.2188 (99.2188)  time: 1.2850  data: 0.7673  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.4715 (0.4779)  acc1: 84.3750 (84.6912)  acc5: 99.6094 (99.3676)  time: 0.5452  data: 0.0311  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.4904 (0.4843)  acc1: 84.3750 (84.5200)  acc5: 99.6094 (99.4100)  time: 0.5218  data: 0.0313  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5538 s / it)\n",
            "* Acc@1 84.520 Acc@5 99.410 loss 0.484\n",
            "Accuracy of the network on the 625 train images: 93.6%\n",
            "Accuracy of the network on the 40 test images: 84.5%\n",
            "Test:  [ 0/40]  eta: 0:00:51  loss: 0.4256 (0.4256)  acc1: 86.7188 (86.7188)  acc5: 99.2188 (99.2188)  time: 1.2751  data: 0.7585  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.4715 (0.4779)  acc1: 84.3750 (84.6912)  acc5: 99.6094 (99.3676)  time: 0.5472  data: 0.0310  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.4904 (0.4843)  acc1: 84.3750 (84.5200)  acc5: 99.6094 (99.4100)  time: 0.5244  data: 0.0311  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5555 s / it)\n",
            "* Acc@1 84.520 Acc@5 99.410 loss 0.484\n",
            "Accuracy of the network on the 40 test images: 84.5%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "\n",
        "    train_stats = evaluate(cifar10_training_loader, model, criterion, device)\n",
        "    test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "    print(f\"Accuracy of the network on the {len(cifar10_training_loader)} train images: {train_stats['acc1']:.1f}%\")\n",
        "    print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate througput\n",
        "start_time = time.time()\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "end_time = time.time()\n",
        "num_samples = len(cifar10_test_loader.dataset)\n",
        "throughput = num_samples / (end_time - start_time)\n",
        "print(\"Throughput: {}\".format(throughput))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5VPTPNrm98",
        "outputId": "95f5c943-630a-4c71-c565-e61f9b2ae402"
      },
      "id": "ec5VPTPNrm98",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:00:51  loss: 0.4256 (0.4256)  acc1: 86.7188 (86.7188)  acc5: 99.2188 (99.2188)  time: 1.2898  data: 0.7756  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.4715 (0.4779)  acc1: 84.3750 (84.6912)  acc5: 99.6094 (99.3676)  time: 0.5580  data: 0.0309  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.4904 (0.4843)  acc1: 84.3750 (84.5200)  acc5: 99.6094 (99.4100)  time: 0.5345  data: 0.0311  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5660 s / it)\n",
            "* Acc@1 84.520 Acc@5 99.410 loss 0.484\n",
            "Throughput: 441.62117512078635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3"
      ],
      "metadata": {
        "id": "jy_PiA4btN8M"
      },
      "id": "jy_PiA4btN8M"
    },
    {
      "cell_type": "code",
      "source": [
        "MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
        "STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n",
        "CHECKPOINT_PATH = './checkpoint'\n",
        "MODEL_NAME = 'vit_tiny_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "shots = 1000\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "cifar10_training_loader = get_training_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=2,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    shots=shots\n",
        ")\n",
        "\n",
        "assert (shots*num_classes == len(cifar10_training_loader.dataset))\n",
        "\n",
        "cifar10_test_loader = get_test_dataloader(\n",
        "    MEAN,\n",
        "    STD,\n",
        "    num_workers=4,\n",
        "    batch_size=256,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2EnRYqDpqeE",
        "outputId": "b2f0efc9-ecb0-46e8-85c5-16ffb149be5c"
      },
      "id": "D2EnRYqDpqeE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_tiny_patch16_224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\" to /root/.cache/torch/hub/checkpoints/deit_tiny_patch16_224-a1311bcf.pth\n",
            "100%|██████████| 21.9M/21.9M [00:00<00:00, 170MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "number of params: 5526346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "\n",
        "    train_stats = evaluate(cifar10_training_loader, model, criterion, device)\n",
        "    test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "    print(f\"Accuracy of the network on the {len(cifar10_training_loader)} train images: {train_stats['acc1']:.1f}%\")\n",
        "    print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvcu7xPxuOBH",
        "outputId": "aa9782f6-71b5-40e0-a4bd-acf3b3b4b7f7"
      },
      "id": "vvcu7xPxuOBH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:02:10  loss: 3.1066 (3.1066)  time: 0.2085  data: 0.1145  max mem: 3781\n",
            "Epoch: [1]  [100/625]  eta: 0:00:20  loss: 2.0346 (2.2067)  time: 0.0377  data: 0.0036  max mem: 3781\n",
            "Epoch: [1]  [200/625]  eta: 0:00:16  loss: 1.9969 (2.1122)  time: 0.0372  data: 0.0033  max mem: 3781\n",
            "Epoch: [1]  [300/625]  eta: 0:00:12  loss: 2.0834 (2.0860)  time: 0.0390  data: 0.0035  max mem: 3781\n",
            "Epoch: [1]  [400/625]  eta: 0:00:08  loss: 1.7889 (2.0483)  time: 0.0375  data: 0.0034  max mem: 3781\n",
            "Epoch: [1]  [500/625]  eta: 0:00:04  loss: 1.7989 (2.0081)  time: 0.0379  data: 0.0034  max mem: 3781\n",
            "Epoch: [1]  [600/625]  eta: 0:00:00  loss: 1.7886 (1.9721)  time: 0.0386  data: 0.0034  max mem: 3781\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 1.5823 (1.9576)  time: 0.0383  data: 0.0035  max mem: 3781\n",
            "Epoch: [1] Total time: 0:00:23 (0.0382 s / it)\n",
            "Averaged stats: loss: 1.5823 (1.9576)\n",
            "Test:  [  0/625]  eta: 0:01:19  loss: 1.5226 (1.5226)  acc1: 37.5000 (37.5000)  acc5: 93.7500 (93.7500)  time: 0.1268  data: 0.1078  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:13  loss: 1.7397 (1.7616)  acc1: 31.2500 (34.5238)  acc5: 87.5000 (87.2024)  time: 0.0174  data: 0.0042  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:11  loss: 1.8080 (1.7882)  acc1: 31.2500 (32.3171)  acc5: 87.5000 (86.8902)  time: 0.0165  data: 0.0034  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:10  loss: 1.7699 (1.7839)  acc1: 31.2500 (33.4016)  acc5: 87.5000 (86.8852)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:09  loss: 1.7228 (1.7864)  acc1: 37.5000 (33.8735)  acc5: 87.5000 (86.7284)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:09  loss: 1.6338 (1.7683)  acc1: 31.2500 (33.4777)  acc5: 87.5000 (87.1906)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:08  loss: 1.6940 (1.7669)  acc1: 31.2500 (33.4194)  acc5: 87.5000 (87.3450)  time: 0.0164  data: 0.0037  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:08  loss: 1.7440 (1.7657)  acc1: 31.2500 (33.5106)  acc5: 87.5000 (87.1454)  time: 0.0162  data: 0.0036  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:08  loss: 1.7190 (1.7671)  acc1: 31.2500 (33.3075)  acc5: 81.2500 (86.9177)  time: 0.0169  data: 0.0037  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:07  loss: 1.8840 (1.7806)  acc1: 25.0000 (32.9420)  acc5: 87.5000 (86.6022)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:07  loss: 1.6742 (1.7804)  acc1: 37.5000 (33.2711)  acc5: 87.5000 (86.6604)  time: 0.0166  data: 0.0033  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:06  loss: 1.6981 (1.7725)  acc1: 31.2500 (33.2579)  acc5: 87.5000 (86.8495)  time: 0.0169  data: 0.0035  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:06  loss: 1.7805 (1.7721)  acc1: 31.2500 (33.2469)  acc5: 87.5000 (86.9554)  time: 0.0165  data: 0.0034  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:06  loss: 1.6977 (1.7684)  acc1: 31.2500 (33.3812)  acc5: 87.5000 (86.9253)  time: 0.0165  data: 0.0034  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:05  loss: 1.7454 (1.7699)  acc1: 31.2500 (33.5409)  acc5: 81.2500 (86.6993)  time: 0.0175  data: 0.0034  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:05  loss: 1.7578 (1.7717)  acc1: 31.2500 (33.5963)  acc5: 87.5000 (86.5241)  time: 0.0169  data: 0.0033  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:05  loss: 1.7403 (1.7748)  acc1: 31.2500 (33.6254)  acc5: 87.5000 (86.3902)  time: 0.0165  data: 0.0034  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:04  loss: 1.7675 (1.7737)  acc1: 31.2500 (33.5227)  acc5: 87.5000 (86.3087)  time: 0.0168  data: 0.0034  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:04  loss: 1.8358 (1.7738)  acc1: 31.2500 (33.3622)  acc5: 81.2500 (86.2188)  time: 0.0166  data: 0.0033  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:04  loss: 1.6918 (1.7734)  acc1: 31.2500 (33.4154)  acc5: 87.5000 (86.1549)  time: 0.0164  data: 0.0033  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:03  loss: 1.7174 (1.7734)  acc1: 31.2500 (33.2918)  acc5: 87.5000 (86.1440)  time: 0.0166  data: 0.0033  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:03  loss: 1.8405 (1.7787)  acc1: 31.2500 (33.2393)  acc5: 87.5000 (86.0748)  time: 0.0164  data: 0.0033  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:03  loss: 1.8498 (1.7834)  acc1: 37.5000 (33.2766)  acc5: 81.2500 (85.9836)  time: 0.0165  data: 0.0033  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:02  loss: 1.8437 (1.7846)  acc1: 37.5000 (33.2972)  acc5: 81.2500 (85.8189)  time: 0.0165  data: 0.0033  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:02  loss: 1.8351 (1.7868)  acc1: 31.2500 (33.2380)  acc5: 81.2500 (85.7588)  time: 0.0165  data: 0.0033  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:02  loss: 1.8858 (1.7906)  acc1: 31.2500 (33.2834)  acc5: 81.2500 (85.6537)  time: 0.0165  data: 0.0033  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:01  loss: 1.8206 (1.7945)  acc1: 31.2500 (33.1454)  acc5: 87.5000 (85.5686)  time: 0.0168  data: 0.0034  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:01  loss: 1.7939 (1.7936)  acc1: 31.2500 (33.1446)  acc5: 87.5000 (85.6169)  time: 0.0165  data: 0.0033  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 1.7364 (1.7931)  acc1: 37.5000 (33.2331)  acc5: 81.2500 (85.5838)  time: 0.0166  data: 0.0033  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:00  loss: 1.6564 (1.7908)  acc1: 31.2500 (33.2509)  acc5: 87.5000 (85.6497)  time: 0.0167  data: 0.0034  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.9140 (1.7940)  acc1: 37.5000 (33.3195)  acc5: 81.2500 (85.5033)  time: 0.0164  data: 0.0035  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.7531 (1.7937)  acc1: 31.2500 (33.3233)  acc5: 81.2500 (85.4368)  time: 0.0172  data: 0.0036  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.7786 (1.7943)  acc1: 31.2500 (33.3600)  acc5: 81.2500 (85.4000)  time: 0.0173  data: 0.0036  max mem: 3781\n",
            "Test: Total time: 0:00:10 (0.0169 s / it)\n",
            "* Acc@1 33.360 Acc@5 85.400 loss 1.794\n",
            "Test:  [ 0/40]  eta: 0:00:36  loss: 1.8340 (1.8340)  acc1: 35.9375 (35.9375)  acc5: 80.4688 (80.4688)  time: 0.9218  data: 0.7751  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:04  loss: 1.8604 (1.8638)  acc1: 30.4688 (31.6406)  acc5: 83.5938 (83.7240)  time: 0.1645  data: 0.0328  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.8560 (1.8626)  acc1: 33.2031 (32.2700)  acc5: 83.5938 (83.5600)  time: 0.1588  data: 0.0327  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1825 s / it)\n",
            "* Acc@1 32.270 Acc@5 83.560 loss 1.863\n",
            "Accuracy of the network on the 625 train images: 33.4%\n",
            "Accuracy of the network on the 40 test images: 32.3%\n",
            "Epoch: [2]  [  0/625]  eta: 0:01:52  loss: 1.8121 (1.8121)  time: 0.1797  data: 0.1146  max mem: 3781\n",
            "Epoch: [2]  [100/625]  eta: 0:00:23  loss: 1.6010 (1.7294)  time: 0.0440  data: 0.0040  max mem: 3781\n",
            "Epoch: [2]  [200/625]  eta: 0:00:18  loss: 1.5975 (1.6776)  time: 0.0417  data: 0.0035  max mem: 3781\n",
            "Epoch: [2]  [300/625]  eta: 0:00:13  loss: 1.4511 (1.6446)  time: 0.0417  data: 0.0037  max mem: 3781\n",
            "Epoch: [2]  [400/625]  eta: 0:00:09  loss: 1.4571 (1.6035)  time: 0.0388  data: 0.0036  max mem: 3781\n",
            "Epoch: [2]  [500/625]  eta: 0:00:05  loss: 1.3470 (1.5604)  time: 0.0377  data: 0.0034  max mem: 3781\n",
            "Epoch: [2]  [600/625]  eta: 0:00:01  loss: 1.2436 (1.5131)  time: 0.0371  data: 0.0034  max mem: 3781\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 1.2536 (1.5062)  time: 0.0373  data: 0.0034  max mem: 3781\n",
            "Epoch: [2] Total time: 0:00:25 (0.0402 s / it)\n",
            "Averaged stats: loss: 1.2536 (1.5062)\n",
            "Test:  [  0/625]  eta: 0:01:19  loss: 1.7800 (1.7800)  acc1: 31.2500 (31.2500)  acc5: 93.7500 (93.7500)  time: 0.1280  data: 0.1091  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:13  loss: 1.3453 (1.3417)  acc1: 50.0000 (51.1905)  acc5: 93.7500 (93.7500)  time: 0.0168  data: 0.0037  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:11  loss: 1.2675 (1.3278)  acc1: 50.0000 (50.7622)  acc5: 93.7500 (92.9878)  time: 0.0168  data: 0.0038  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:10  loss: 1.2392 (1.2999)  acc1: 56.2500 (52.5615)  acc5: 93.7500 (93.7500)  time: 0.0164  data: 0.0035  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:09  loss: 1.2282 (1.3031)  acc1: 56.2500 (52.3920)  acc5: 100.0000 (94.4444)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:09  loss: 1.3184 (1.3123)  acc1: 50.0000 (52.2896)  acc5: 93.7500 (94.3069)  time: 0.0166  data: 0.0035  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:08  loss: 1.3460 (1.3197)  acc1: 43.7500 (51.0847)  acc5: 93.7500 (94.2665)  time: 0.0164  data: 0.0035  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:08  loss: 1.3052 (1.3231)  acc1: 50.0000 (51.1082)  acc5: 93.7500 (94.3262)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:08  loss: 1.2044 (1.3200)  acc1: 56.2500 (51.4363)  acc5: 93.7500 (94.1770)  time: 0.0171  data: 0.0035  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:07  loss: 1.0630 (1.2965)  acc1: 56.2500 (52.2099)  acc5: 100.0000 (94.5097)  time: 0.0169  data: 0.0035  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:07  loss: 1.2611 (1.2958)  acc1: 56.2500 (52.3010)  acc5: 93.7500 (94.6206)  time: 0.0173  data: 0.0036  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:06  loss: 1.1498 (1.2891)  acc1: 56.2500 (52.7432)  acc5: 93.7500 (94.5419)  time: 0.0169  data: 0.0035  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:06  loss: 1.3361 (1.2990)  acc1: 43.7500 (52.3340)  acc5: 93.7500 (94.3724)  time: 0.0167  data: 0.0034  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:06  loss: 1.2110 (1.2930)  acc1: 56.2500 (52.7059)  acc5: 100.0000 (94.5402)  time: 0.0167  data: 0.0034  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:05  loss: 1.2825 (1.2952)  acc1: 50.0000 (52.6246)  acc5: 93.7500 (94.4395)  time: 0.0172  data: 0.0034  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:05  loss: 1.2985 (1.2948)  acc1: 50.0000 (52.6370)  acc5: 93.7500 (94.5183)  time: 0.0166  data: 0.0035  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:05  loss: 1.1392 (1.2875)  acc1: 56.2500 (52.7648)  acc5: 100.0000 (94.6456)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:04  loss: 1.2142 (1.2838)  acc1: 50.0000 (52.9692)  acc5: 100.0000 (94.7214)  time: 0.0166  data: 0.0035  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:04  loss: 1.2882 (1.2835)  acc1: 50.0000 (52.8393)  acc5: 93.7500 (94.7542)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:04  loss: 1.2927 (1.2838)  acc1: 50.0000 (52.7887)  acc5: 93.7500 (94.7835)  time: 0.0167  data: 0.0035  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:03  loss: 1.2052 (1.2802)  acc1: 50.0000 (52.8522)  acc5: 93.7500 (94.8722)  time: 0.0172  data: 0.0035  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:03  loss: 1.1630 (1.2788)  acc1: 56.2500 (52.9543)  acc5: 100.0000 (94.9525)  time: 0.0168  data: 0.0035  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:03  loss: 1.3046 (1.2795)  acc1: 50.0000 (52.8770)  acc5: 93.7500 (94.9972)  time: 0.0167  data: 0.0034  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:02  loss: 1.2781 (1.2797)  acc1: 56.2500 (52.9826)  acc5: 93.7500 (94.9566)  time: 0.0171  data: 0.0035  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:02  loss: 1.1142 (1.2752)  acc1: 56.2500 (53.1445)  acc5: 100.0000 (95.0364)  time: 0.0167  data: 0.0034  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:02  loss: 1.1402 (1.2723)  acc1: 56.2500 (53.1687)  acc5: 100.0000 (95.1347)  time: 0.0167  data: 0.0034  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:01  loss: 1.2847 (1.2735)  acc1: 50.0000 (53.0830)  acc5: 100.0000 (95.1655)  time: 0.0170  data: 0.0037  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:01  loss: 1.2882 (1.2754)  acc1: 50.0000 (53.0152)  acc5: 93.7500 (95.0901)  time: 0.0168  data: 0.0034  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 1.2361 (1.2768)  acc1: 56.2500 (52.9523)  acc5: 93.7500 (95.0758)  time: 0.0165  data: 0.0033  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:00  loss: 1.4185 (1.2797)  acc1: 43.7500 (52.7861)  acc5: 93.7500 (95.0516)  time: 0.0169  data: 0.0034  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 1.2505 (1.2798)  acc1: 50.0000 (52.7246)  acc5: 93.7500 (95.0499)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 1.2409 (1.2800)  acc1: 50.0000 (52.7375)  acc5: 100.0000 (95.1288)  time: 0.0162  data: 0.0034  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 1.2922 (1.2805)  acc1: 50.0000 (52.7100)  acc5: 100.0000 (95.1400)  time: 0.0161  data: 0.0034  max mem: 3781\n",
            "Test: Total time: 0:00:10 (0.0170 s / it)\n",
            "* Acc@1 52.710 Acc@5 95.140 loss 1.280\n",
            "Test:  [ 0/40]  eta: 0:00:35  loss: 1.4378 (1.4378)  acc1: 46.0938 (46.0938)  acc5: 92.1875 (92.1875)  time: 0.8882  data: 0.7480  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:03  loss: 1.3473 (1.3595)  acc1: 49.6094 (49.9070)  acc5: 92.9688 (93.2664)  time: 0.1644  data: 0.0327  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.3515 (1.3613)  acc1: 48.4375 (49.6400)  acc5: 93.7500 (93.3400)  time: 0.1580  data: 0.0322  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1811 s / it)\n",
            "* Acc@1 49.640 Acc@5 93.340 loss 1.361\n",
            "Accuracy of the network on the 625 train images: 52.7%\n",
            "Accuracy of the network on the 40 test images: 49.6%\n",
            "Epoch: [3]  [  0/625]  eta: 0:01:40  loss: 0.9039 (0.9039)  time: 0.1613  data: 0.1114  max mem: 3781\n",
            "Epoch: [3]  [100/625]  eta: 0:00:20  loss: 1.0451 (1.1917)  time: 0.0375  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [200/625]  eta: 0:00:16  loss: 1.1099 (1.1767)  time: 0.0377  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [300/625]  eta: 0:00:12  loss: 1.2097 (1.1808)  time: 0.0378  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [400/625]  eta: 0:00:08  loss: 1.0458 (1.1600)  time: 0.0373  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [500/625]  eta: 0:00:04  loss: 1.0909 (1.1459)  time: 0.0386  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [600/625]  eta: 0:00:00  loss: 1.0303 (1.1333)  time: 0.0373  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.8692 (1.1270)  time: 0.0375  data: 0.0035  max mem: 3781\n",
            "Epoch: [3] Total time: 0:00:23 (0.0383 s / it)\n",
            "Averaged stats: loss: 0.8692 (1.1270)\n",
            "Test:  [  0/625]  eta: 0:01:21  loss: 0.7591 (0.7591)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.1296  data: 0.1108  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:13  loss: 0.8096 (0.8585)  acc1: 68.7500 (68.4524)  acc5: 100.0000 (97.9167)  time: 0.0170  data: 0.0038  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:11  loss: 0.9158 (0.8912)  acc1: 68.7500 (68.1402)  acc5: 100.0000 (98.4756)  time: 0.0168  data: 0.0037  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:10  loss: 0.9945 (0.9268)  acc1: 68.7500 (67.9303)  acc5: 93.7500 (97.8484)  time: 0.0167  data: 0.0034  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:09  loss: 0.9335 (0.9232)  acc1: 68.7500 (67.6698)  acc5: 100.0000 (97.7623)  time: 0.0161  data: 0.0034  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:09  loss: 0.9784 (0.9399)  acc1: 68.7500 (67.1411)  acc5: 100.0000 (97.7723)  time: 0.0163  data: 0.0033  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:08  loss: 0.8427 (0.9314)  acc1: 68.7500 (67.5103)  acc5: 100.0000 (97.8306)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:08  loss: 0.8883 (0.9237)  acc1: 68.7500 (67.8191)  acc5: 100.0000 (97.8723)  time: 0.0162  data: 0.0033  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:07  loss: 0.9650 (0.9262)  acc1: 62.5000 (67.6630)  acc5: 100.0000 (97.8649)  time: 0.0162  data: 0.0033  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:07  loss: 0.9841 (0.9272)  acc1: 68.7500 (67.7486)  acc5: 100.0000 (97.7555)  time: 0.0163  data: 0.0033  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:07  loss: 0.8707 (0.9308)  acc1: 62.5000 (67.7239)  acc5: 100.0000 (97.7301)  time: 0.0161  data: 0.0034  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:06  loss: 0.9223 (0.9362)  acc1: 62.5000 (67.4774)  acc5: 100.0000 (97.6244)  time: 0.0167  data: 0.0035  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:06  loss: 0.8041 (0.9325)  acc1: 75.0000 (67.7386)  acc5: 100.0000 (97.5882)  time: 0.0164  data: 0.0036  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:06  loss: 0.8478 (0.9311)  acc1: 68.7500 (67.7203)  acc5: 100.0000 (97.6054)  time: 0.0165  data: 0.0037  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:05  loss: 0.8689 (0.9293)  acc1: 68.7500 (67.6601)  acc5: 93.7500 (97.4867)  time: 0.0169  data: 0.0039  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:05  loss: 0.8678 (0.9322)  acc1: 68.7500 (67.5872)  acc5: 93.7500 (97.2799)  time: 0.0169  data: 0.0037  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:05  loss: 0.9109 (0.9337)  acc1: 62.5000 (67.2897)  acc5: 100.0000 (97.2936)  time: 0.0165  data: 0.0036  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:04  loss: 0.8206 (0.9313)  acc1: 68.7500 (67.3387)  acc5: 100.0000 (97.3424)  time: 0.0163  data: 0.0033  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:04  loss: 0.7907 (0.9281)  acc1: 68.7500 (67.4688)  acc5: 100.0000 (97.4030)  time: 0.0163  data: 0.0033  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:04  loss: 0.9513 (0.9259)  acc1: 68.7500 (67.6837)  acc5: 100.0000 (97.4245)  time: 0.0163  data: 0.0033  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:03  loss: 0.8920 (0.9290)  acc1: 68.7500 (67.5966)  acc5: 93.7500 (97.3660)  time: 0.0172  data: 0.0036  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:03  loss: 0.9099 (0.9318)  acc1: 62.5000 (67.4584)  acc5: 100.0000 (97.3426)  time: 0.0165  data: 0.0036  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:03  loss: 0.8061 (0.9275)  acc1: 68.7500 (67.5879)  acc5: 100.0000 (97.3923)  time: 0.0167  data: 0.0035  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:02  loss: 1.0428 (0.9337)  acc1: 62.5000 (67.3807)  acc5: 100.0000 (97.3834)  time: 0.0169  data: 0.0035  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:02  loss: 0.7305 (0.9278)  acc1: 75.0000 (67.6195)  acc5: 100.0000 (97.4272)  time: 0.0181  data: 0.0038  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:02  loss: 0.9190 (0.9280)  acc1: 68.7500 (67.6896)  acc5: 100.0000 (97.4052)  time: 0.0162  data: 0.0034  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:01  loss: 0.9196 (0.9274)  acc1: 68.7500 (67.7063)  acc5: 100.0000 (97.4088)  time: 0.0162  data: 0.0035  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:01  loss: 0.9468 (0.9303)  acc1: 62.5000 (67.6294)  acc5: 100.0000 (97.4469)  time: 0.0162  data: 0.0035  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 0.9610 (0.9320)  acc1: 62.5000 (67.5579)  acc5: 100.0000 (97.4822)  time: 0.0162  data: 0.0035  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:00  loss: 1.0101 (0.9361)  acc1: 62.5000 (67.4376)  acc5: 100.0000 (97.4720)  time: 0.0162  data: 0.0035  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 0.9076 (0.9361)  acc1: 68.7500 (67.4397)  acc5: 100.0000 (97.5146)  time: 0.0169  data: 0.0035  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 0.9430 (0.9367)  acc1: 62.5000 (67.4014)  acc5: 100.0000 (97.5040)  time: 0.0172  data: 0.0037  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 0.8411 (0.9365)  acc1: 68.7500 (67.4300)  acc5: 100.0000 (97.5000)  time: 0.0173  data: 0.0037  max mem: 3781\n",
            "Test: Total time: 0:00:10 (0.0169 s / it)\n",
            "* Acc@1 67.430 Acc@5 97.500 loss 0.936\n",
            "Test:  [ 0/40]  eta: 0:00:35  loss: 1.0384 (1.0384)  acc1: 64.8438 (64.8438)  acc5: 97.6562 (97.6562)  time: 0.8938  data: 0.7623  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:03  loss: 1.0415 (1.0529)  acc1: 62.8906 (63.1882)  acc5: 96.4844 (96.6518)  time: 0.1639  data: 0.0324  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.0635 (1.0495)  acc1: 62.5000 (63.1900)  acc5: 97.2656 (96.7800)  time: 0.1576  data: 0.0322  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1806 s / it)\n",
            "* Acc@1 63.190 Acc@5 96.780 loss 1.050\n",
            "Accuracy of the network on the 625 train images: 67.4%\n",
            "Accuracy of the network on the 40 test images: 63.2%\n",
            "Epoch: [4]  [  0/625]  eta: 0:01:46  loss: 0.7584 (0.7584)  time: 0.1704  data: 0.1100  max mem: 3781\n",
            "Epoch: [4]  [100/625]  eta: 0:00:21  loss: 0.9307 (0.9551)  time: 0.0406  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [200/625]  eta: 0:00:16  loss: 0.9170 (0.9356)  time: 0.0369  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [300/625]  eta: 0:00:12  loss: 0.9650 (0.9505)  time: 0.0378  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [400/625]  eta: 0:00:08  loss: 0.9329 (0.9358)  time: 0.0417  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [500/625]  eta: 0:00:04  loss: 0.8363 (0.9300)  time: 0.0374  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [600/625]  eta: 0:00:00  loss: 0.7541 (0.9197)  time: 0.0371  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.8026 (0.9176)  time: 0.0376  data: 0.0035  max mem: 3781\n",
            "Epoch: [4] Total time: 0:00:24 (0.0388 s / it)\n",
            "Averaged stats: loss: 0.8026 (0.9176)\n",
            "Test:  [  0/625]  eta: 0:01:25  loss: 1.0236 (1.0236)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 0.1374  data: 0.1186  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:13  loss: 0.7060 (0.7064)  acc1: 75.0000 (73.8095)  acc5: 100.0000 (98.8095)  time: 0.0173  data: 0.0041  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:11  loss: 0.8036 (0.7513)  acc1: 75.0000 (73.0183)  acc5: 100.0000 (98.4756)  time: 0.0177  data: 0.0039  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:10  loss: 0.8225 (0.7660)  acc1: 75.0000 (73.0533)  acc5: 100.0000 (98.6680)  time: 0.0167  data: 0.0037  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:10  loss: 0.7951 (0.7685)  acc1: 68.7500 (72.4537)  acc5: 100.0000 (98.6883)  time: 0.0164  data: 0.0036  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:09  loss: 0.6579 (0.7582)  acc1: 75.0000 (72.7104)  acc5: 100.0000 (98.7624)  time: 0.0166  data: 0.0038  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:09  loss: 0.6480 (0.7545)  acc1: 75.0000 (72.9855)  acc5: 100.0000 (98.7603)  time: 0.0162  data: 0.0035  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:08  loss: 0.7118 (0.7512)  acc1: 68.7500 (73.1826)  acc5: 100.0000 (98.8918)  time: 0.0161  data: 0.0033  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:08  loss: 0.7428 (0.7602)  acc1: 68.7500 (72.8261)  acc5: 100.0000 (98.9130)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:07  loss: 0.7009 (0.7608)  acc1: 75.0000 (72.8936)  acc5: 100.0000 (98.8605)  time: 0.0171  data: 0.0035  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:07  loss: 0.7432 (0.7631)  acc1: 75.0000 (73.0721)  acc5: 100.0000 (98.7562)  time: 0.0164  data: 0.0035  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:06  loss: 0.7005 (0.7616)  acc1: 75.0000 (73.0486)  acc5: 100.0000 (98.7839)  time: 0.0166  data: 0.0036  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:06  loss: 0.7389 (0.7643)  acc1: 75.0000 (72.9772)  acc5: 100.0000 (98.7811)  time: 0.0164  data: 0.0036  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:06  loss: 0.7892 (0.7639)  acc1: 75.0000 (73.0364)  acc5: 100.0000 (98.8027)  time: 0.0162  data: 0.0034  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:05  loss: 0.7867 (0.7662)  acc1: 75.0000 (72.9760)  acc5: 100.0000 (98.7544)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:05  loss: 0.9129 (0.7750)  acc1: 68.7500 (72.7990)  acc5: 100.0000 (98.6919)  time: 0.0164  data: 0.0035  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:05  loss: 0.7023 (0.7704)  acc1: 68.7500 (72.8777)  acc5: 100.0000 (98.7734)  time: 0.0166  data: 0.0037  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:04  loss: 0.6609 (0.7656)  acc1: 75.0000 (72.9655)  acc5: 100.0000 (98.8087)  time: 0.0162  data: 0.0034  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:04  loss: 0.7042 (0.7681)  acc1: 75.0000 (72.8878)  acc5: 100.0000 (98.7881)  time: 0.0168  data: 0.0036  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:04  loss: 0.7577 (0.7669)  acc1: 75.0000 (72.8839)  acc5: 100.0000 (98.8025)  time: 0.0166  data: 0.0035  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:03  loss: 0.7582 (0.7708)  acc1: 68.7500 (72.7244)  acc5: 100.0000 (98.7843)  time: 0.0169  data: 0.0035  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:03  loss: 0.6197 (0.7659)  acc1: 81.2500 (72.8919)  acc5: 100.0000 (98.7678)  time: 0.0174  data: 0.0035  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:03  loss: 0.6749 (0.7653)  acc1: 75.0000 (72.8883)  acc5: 100.0000 (98.7670)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:02  loss: 0.7859 (0.7695)  acc1: 68.7500 (72.8308)  acc5: 100.0000 (98.7256)  time: 0.0170  data: 0.0036  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:02  loss: 0.7519 (0.7702)  acc1: 75.0000 (72.7651)  acc5: 100.0000 (98.7006)  time: 0.0167  data: 0.0036  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:02  loss: 0.7099 (0.7685)  acc1: 75.0000 (72.9167)  acc5: 100.0000 (98.6901)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:01  loss: 0.7114 (0.7664)  acc1: 75.0000 (73.0326)  acc5: 100.0000 (98.7164)  time: 0.0168  data: 0.0034  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:01  loss: 0.6800 (0.7669)  acc1: 75.0000 (72.9898)  acc5: 100.0000 (98.7408)  time: 0.0168  data: 0.0034  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 0.7128 (0.7644)  acc1: 75.0000 (73.1395)  acc5: 100.0000 (98.7077)  time: 0.0165  data: 0.0034  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:00  loss: 0.7421 (0.7657)  acc1: 75.0000 (73.1175)  acc5: 100.0000 (98.6876)  time: 0.0166  data: 0.0035  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 0.7421 (0.7662)  acc1: 68.7500 (73.0137)  acc5: 100.0000 (98.6897)  time: 0.0164  data: 0.0035  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 0.6239 (0.7620)  acc1: 81.2500 (73.1582)  acc5: 100.0000 (98.6916)  time: 0.0162  data: 0.0034  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 0.6156 (0.7606)  acc1: 81.2500 (73.2100)  acc5: 100.0000 (98.6900)  time: 0.0161  data: 0.0034  max mem: 3781\n",
            "Test: Total time: 0:00:10 (0.0169 s / it)\n",
            "* Acc@1 73.210 Acc@5 98.690 loss 0.761\n",
            "Test:  [ 0/40]  eta: 0:00:35  loss: 0.9473 (0.9473)  acc1: 66.7969 (66.7969)  acc5: 98.4375 (98.4375)  time: 0.8960  data: 0.7598  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:04  loss: 0.9136 (0.9330)  acc1: 66.7969 (67.0759)  acc5: 97.6562 (97.7307)  time: 0.1654  data: 0.0338  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.9266 (0.9286)  acc1: 67.1875 (67.1600)  acc5: 98.0469 (97.7100)  time: 0.1588  data: 0.0330  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1821 s / it)\n",
            "* Acc@1 67.160 Acc@5 97.710 loss 0.929\n",
            "Accuracy of the network on the 625 train images: 73.2%\n",
            "Accuracy of the network on the 40 test images: 67.2%\n",
            "Epoch: [5]  [  0/625]  eta: 0:01:44  loss: 0.8131 (0.8131)  time: 0.1667  data: 0.1161  max mem: 3781\n",
            "Epoch: [5]  [100/625]  eta: 0:00:20  loss: 0.7472 (0.7396)  time: 0.0371  data: 0.0033  max mem: 3781\n",
            "Epoch: [5]  [200/625]  eta: 0:00:16  loss: 0.7719 (0.7688)  time: 0.0372  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [300/625]  eta: 0:00:12  loss: 0.7736 (0.7699)  time: 0.0372  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [400/625]  eta: 0:00:08  loss: 0.8189 (0.7837)  time: 0.0372  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [500/625]  eta: 0:00:04  loss: 0.8161 (0.7861)  time: 0.0370  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [600/625]  eta: 0:00:00  loss: 0.7343 (0.7861)  time: 0.0379  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.7225 (0.7877)  time: 0.0376  data: 0.0034  max mem: 3781\n",
            "Epoch: [5] Total time: 0:00:23 (0.0380 s / it)\n",
            "Averaged stats: loss: 0.7225 (0.7877)\n",
            "Test:  [  0/625]  eta: 0:01:20  loss: 0.8100 (0.8100)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 0.1287  data: 0.1098  max mem: 3781\n",
            "Test:  [ 20/625]  eta: 0:00:13  loss: 0.6299 (0.6821)  acc1: 75.0000 (78.2738)  acc5: 100.0000 (98.5119)  time: 0.0170  data: 0.0037  max mem: 3781\n",
            "Test:  [ 40/625]  eta: 0:00:11  loss: 0.6755 (0.7002)  acc1: 75.0000 (74.6951)  acc5: 100.0000 (98.7805)  time: 0.0163  data: 0.0034  max mem: 3781\n",
            "Test:  [ 60/625]  eta: 0:00:10  loss: 0.7069 (0.7142)  acc1: 75.0000 (75.5123)  acc5: 100.0000 (98.6680)  time: 0.0166  data: 0.0035  max mem: 3781\n",
            "Test:  [ 80/625]  eta: 0:00:09  loss: 0.6514 (0.6954)  acc1: 75.0000 (76.1574)  acc5: 100.0000 (98.6111)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [100/625]  eta: 0:00:09  loss: 0.5487 (0.6799)  acc1: 81.2500 (76.5470)  acc5: 100.0000 (98.7005)  time: 0.0163  data: 0.0035  max mem: 3781\n",
            "Test:  [120/625]  eta: 0:00:08  loss: 0.5846 (0.6828)  acc1: 81.2500 (76.8595)  acc5: 100.0000 (98.6054)  time: 0.0163  data: 0.0035  max mem: 3781\n",
            "Test:  [140/625]  eta: 0:00:08  loss: 0.6603 (0.6832)  acc1: 75.0000 (76.6401)  acc5: 100.0000 (98.6702)  time: 0.0162  data: 0.0034  max mem: 3781\n",
            "Test:  [160/625]  eta: 0:00:07  loss: 0.6081 (0.6855)  acc1: 75.0000 (76.5916)  acc5: 100.0000 (98.7189)  time: 0.0162  data: 0.0034  max mem: 3781\n",
            "Test:  [180/625]  eta: 0:00:07  loss: 0.5970 (0.6823)  acc1: 75.0000 (76.6920)  acc5: 100.0000 (98.8260)  time: 0.0163  data: 0.0033  max mem: 3781\n",
            "Test:  [200/625]  eta: 0:00:07  loss: 0.5964 (0.6777)  acc1: 75.0000 (76.8035)  acc5: 100.0000 (98.8184)  time: 0.0169  data: 0.0034  max mem: 3781\n",
            "Test:  [220/625]  eta: 0:00:06  loss: 0.7296 (0.6800)  acc1: 75.0000 (76.4989)  acc5: 100.0000 (98.7839)  time: 0.0162  data: 0.0033  max mem: 3781\n",
            "Test:  [240/625]  eta: 0:00:06  loss: 0.6878 (0.6910)  acc1: 68.7500 (75.9595)  acc5: 100.0000 (98.7811)  time: 0.0166  data: 0.0035  max mem: 3781\n",
            "Test:  [260/625]  eta: 0:00:06  loss: 0.5817 (0.6893)  acc1: 75.0000 (76.0536)  acc5: 100.0000 (98.8266)  time: 0.0167  data: 0.0035  max mem: 3781\n",
            "Test:  [280/625]  eta: 0:00:05  loss: 0.6532 (0.6911)  acc1: 75.0000 (75.9786)  acc5: 100.0000 (98.8212)  time: 0.0178  data: 0.0037  max mem: 3781\n",
            "Test:  [300/625]  eta: 0:00:05  loss: 0.6847 (0.6948)  acc1: 75.0000 (75.8098)  acc5: 100.0000 (98.7542)  time: 0.0174  data: 0.0036  max mem: 3781\n",
            "Test:  [320/625]  eta: 0:00:05  loss: 0.6755 (0.6937)  acc1: 81.2500 (75.9151)  acc5: 100.0000 (98.7928)  time: 0.0171  data: 0.0036  max mem: 3781\n",
            "Test:  [340/625]  eta: 0:00:04  loss: 0.5868 (0.6925)  acc1: 75.0000 (75.9348)  acc5: 100.0000 (98.7537)  time: 0.0175  data: 0.0038  max mem: 3781\n",
            "Test:  [360/625]  eta: 0:00:04  loss: 0.5971 (0.6915)  acc1: 75.0000 (75.9522)  acc5: 100.0000 (98.7881)  time: 0.0180  data: 0.0038  max mem: 3781\n",
            "Test:  [380/625]  eta: 0:00:04  loss: 0.6258 (0.6856)  acc1: 81.2500 (76.2303)  acc5: 100.0000 (98.8025)  time: 0.0167  data: 0.0036  max mem: 3781\n",
            "Test:  [400/625]  eta: 0:00:03  loss: 0.6950 (0.6866)  acc1: 75.0000 (76.2313)  acc5: 100.0000 (98.8155)  time: 0.0172  data: 0.0034  max mem: 3781\n",
            "Test:  [420/625]  eta: 0:00:03  loss: 0.6488 (0.6853)  acc1: 75.0000 (76.3361)  acc5: 100.0000 (98.8420)  time: 0.0165  data: 0.0035  max mem: 3781\n",
            "Test:  [440/625]  eta: 0:00:03  loss: 0.5510 (0.6812)  acc1: 75.0000 (76.3889)  acc5: 100.0000 (98.7954)  time: 0.0166  data: 0.0036  max mem: 3781\n",
            "Test:  [460/625]  eta: 0:00:02  loss: 0.6043 (0.6802)  acc1: 75.0000 (76.3693)  acc5: 100.0000 (98.8205)  time: 0.0170  data: 0.0037  max mem: 3781\n",
            "Test:  [480/625]  eta: 0:00:02  loss: 0.6695 (0.6811)  acc1: 68.7500 (76.2084)  acc5: 100.0000 (98.8565)  time: 0.0172  data: 0.0037  max mem: 3781\n",
            "Test:  [500/625]  eta: 0:00:02  loss: 0.6424 (0.6815)  acc1: 75.0000 (76.1352)  acc5: 100.0000 (98.8648)  time: 0.0169  data: 0.0036  max mem: 3781\n",
            "Test:  [520/625]  eta: 0:00:01  loss: 0.6215 (0.6796)  acc1: 75.0000 (76.1636)  acc5: 100.0000 (98.8484)  time: 0.0169  data: 0.0036  max mem: 3781\n",
            "Test:  [540/625]  eta: 0:00:01  loss: 0.5933 (0.6764)  acc1: 81.2500 (76.3517)  acc5: 100.0000 (98.8909)  time: 0.0168  data: 0.0037  max mem: 3781\n",
            "Test:  [560/625]  eta: 0:00:01  loss: 0.5377 (0.6738)  acc1: 81.2500 (76.4149)  acc5: 100.0000 (98.8971)  time: 0.0170  data: 0.0036  max mem: 3781\n",
            "Test:  [580/625]  eta: 0:00:00  loss: 0.6616 (0.6741)  acc1: 75.0000 (76.4200)  acc5: 100.0000 (98.8920)  time: 0.0166  data: 0.0036  max mem: 3781\n",
            "Test:  [600/625]  eta: 0:00:00  loss: 0.8072 (0.6766)  acc1: 75.0000 (76.3415)  acc5: 100.0000 (98.8769)  time: 0.0163  data: 0.0035  max mem: 3781\n",
            "Test:  [620/625]  eta: 0:00:00  loss: 0.7635 (0.6793)  acc1: 68.7500 (76.1574)  acc5: 100.0000 (98.9130)  time: 0.0174  data: 0.0036  max mem: 3781\n",
            "Test:  [624/625]  eta: 0:00:00  loss: 0.7755 (0.6806)  acc1: 68.7500 (76.1000)  acc5: 100.0000 (98.9200)  time: 0.0173  data: 0.0036  max mem: 3781\n",
            "Test: Total time: 0:00:10 (0.0171 s / it)\n",
            "* Acc@1 76.100 Acc@5 98.920 loss 0.681\n",
            "Test:  [ 0/40]  eta: 0:00:35  loss: 0.9639 (0.9639)  acc1: 66.0156 (66.0156)  acc5: 96.8750 (96.8750)  time: 0.8920  data: 0.7595  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:04  loss: 0.9031 (0.8991)  acc1: 67.1875 (67.6525)  acc5: 97.2656 (97.4702)  time: 0.1663  data: 0.0345  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.8795 (0.8887)  acc1: 66.7969 (67.7400)  acc5: 98.0469 (97.6300)  time: 0.1584  data: 0.0327  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1821 s / it)\n",
            "* Acc@1 67.740 Acc@5 97.630 loss 0.889\n",
            "Accuracy of the network on the 625 train images: 76.1%\n",
            "Accuracy of the network on the 40 test images: 67.7%\n",
            "Test:  [ 0/40]  eta: 0:00:36  loss: 0.9639 (0.9639)  acc1: 66.0156 (66.0156)  acc5: 96.8750 (96.8750)  time: 0.9216  data: 0.7861  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:03  loss: 0.9031 (0.8991)  acc1: 67.1875 (67.6525)  acc5: 97.2656 (97.4702)  time: 0.1637  data: 0.0326  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.8795 (0.8887)  acc1: 66.7969 (67.7400)  acc5: 98.0469 (97.6300)  time: 0.1578  data: 0.0322  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1813 s / it)\n",
            "* Acc@1 67.740 Acc@5 97.630 loss 0.889\n",
            "Accuracy of the network on the 40 test images: 67.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e323d040",
      "metadata": {
        "id": "e323d040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419a4997-1e94-405d-bb1f-20b1beed15f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:00:35  loss: 0.9639 (0.9639)  acc1: 66.0156 (66.0156)  acc5: 96.8750 (96.8750)  time: 0.8943  data: 0.7615  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:03  loss: 0.9031 (0.8991)  acc1: 67.1875 (67.6525)  acc5: 97.2656 (97.4702)  time: 0.1650  data: 0.0329  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.8795 (0.8887)  acc1: 66.7969 (67.7400)  acc5: 98.0469 (97.6300)  time: 0.1586  data: 0.0327  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1815 s / it)\n",
            "* Acc@1 67.740 Acc@5 97.630 loss 0.889\n",
            "Throughput: 1376.0974434723805\n"
          ]
        }
      ],
      "source": [
        "# Calculate througput\n",
        "start_time = time.time()\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "end_time = time.time()\n",
        "num_samples = len(cifar10_test_loader.dataset)\n",
        "throughput = num_samples / (end_time - start_time)\n",
        "print(\"Throughput: {}\".format(throughput))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWKAL0qczTe8"
      },
      "id": "DWKAL0qczTe8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4"
      ],
      "metadata": {
        "id": "siSER43KzTvG"
      },
      "id": "siSER43KzTvG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caaf4f8a",
      "metadata": {
        "id": "caaf4f8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f63cdf-dac1-405e-a39c-69a96197e152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model: vit_base_patch16_224\n",
            "number of params: 85806346\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Train the teacher\n",
        "\n",
        "MODEL_NAME = 'vit_base_patch16_224'\n",
        "num_classes = 10\n",
        "EPOCHS = 5\n",
        "LR = 0.0001\n",
        "WD = 0.0\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "teacher = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "teacher = teacher.to(device)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(teacher.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in teacher.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c392f94",
      "metadata": {
        "id": "6c392f94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbe1c6a-3e71-41f4-806f-50e71f3d8e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:02:14  loss: 0.4484 (0.4484)  time: 0.2148  data: 0.1134  max mem: 3781\n",
            "Epoch: [1]  [100/625]  eta: 0:00:54  loss: 0.2361 (0.2730)  time: 0.1028  data: 0.0036  max mem: 3781\n",
            "Epoch: [1]  [200/625]  eta: 0:00:43  loss: 0.2619 (0.2809)  time: 0.1027  data: 0.0036  max mem: 3781\n",
            "Epoch: [1]  [300/625]  eta: 0:00:33  loss: 0.1310 (0.2651)  time: 0.1021  data: 0.0036  max mem: 3781\n",
            "Epoch: [1]  [400/625]  eta: 0:00:23  loss: 0.1814 (0.2737)  time: 0.1014  data: 0.0035  max mem: 3781\n",
            "Epoch: [1]  [500/625]  eta: 0:00:12  loss: 0.2724 (0.2758)  time: 0.1010  data: 0.0035  max mem: 3781\n",
            "Epoch: [1]  [600/625]  eta: 0:00:02  loss: 0.1551 (0.2791)  time: 0.1009  data: 0.0034  max mem: 3781\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 0.1731 (0.2786)  time: 0.1011  data: 0.0036  max mem: 3781\n",
            "Epoch: [1] Total time: 0:01:03 (0.1022 s / it)\n",
            "Averaged stats: loss: 0.1731 (0.2786)\n",
            "Epoch: [2]  [  0/625]  eta: 0:02:14  loss: 0.2355 (0.2355)  time: 0.2146  data: 0.1094  max mem: 3781\n",
            "Epoch: [2]  [100/625]  eta: 0:00:53  loss: 0.1195 (0.1928)  time: 0.1008  data: 0.0035  max mem: 3781\n",
            "Epoch: [2]  [200/625]  eta: 0:00:43  loss: 0.2516 (0.2226)  time: 0.1009  data: 0.0034  max mem: 3781\n",
            "Epoch: [2]  [300/625]  eta: 0:00:32  loss: 0.1455 (0.2276)  time: 0.1015  data: 0.0036  max mem: 3781\n",
            "Epoch: [2]  [400/625]  eta: 0:00:22  loss: 0.1162 (0.2248)  time: 0.1014  data: 0.0035  max mem: 3781\n",
            "Epoch: [2]  [500/625]  eta: 0:00:12  loss: 0.1967 (0.2277)  time: 0.1017  data: 0.0035  max mem: 3781\n",
            "Epoch: [2]  [600/625]  eta: 0:00:02  loss: 0.2984 (0.2308)  time: 0.1021  data: 0.0035  max mem: 3781\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 0.2003 (0.2314)  time: 0.1016  data: 0.0035  max mem: 3781\n",
            "Epoch: [2] Total time: 0:01:03 (0.1017 s / it)\n",
            "Averaged stats: loss: 0.2003 (0.2314)\n",
            "Epoch: [3]  [  0/625]  eta: 0:02:10  loss: 0.1497 (0.1497)  time: 0.2096  data: 0.1109  max mem: 3781\n",
            "Epoch: [3]  [100/625]  eta: 0:00:53  loss: 0.1716 (0.1422)  time: 0.1012  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [200/625]  eta: 0:00:43  loss: 0.1567 (0.1765)  time: 0.1016  data: 0.0037  max mem: 3781\n",
            "Epoch: [3]  [300/625]  eta: 0:00:33  loss: 0.2401 (0.1738)  time: 0.1012  data: 0.0036  max mem: 3781\n",
            "Epoch: [3]  [400/625]  eta: 0:00:22  loss: 0.1397 (0.1837)  time: 0.1013  data: 0.0036  max mem: 3781\n",
            "Epoch: [3]  [500/625]  eta: 0:00:12  loss: 0.2039 (0.1854)  time: 0.1012  data: 0.0036  max mem: 3781\n",
            "Epoch: [3]  [600/625]  eta: 0:00:02  loss: 0.1134 (0.1948)  time: 0.1018  data: 0.0037  max mem: 3781\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.1292 (0.1944)  time: 0.1015  data: 0.0036  max mem: 3781\n",
            "Epoch: [3] Total time: 0:01:03 (0.1018 s / it)\n",
            "Averaged stats: loss: 0.1292 (0.1944)\n",
            "Epoch: [4]  [  0/625]  eta: 0:02:11  loss: 0.0702 (0.0702)  time: 0.2099  data: 0.1127  max mem: 3781\n",
            "Epoch: [4]  [100/625]  eta: 0:00:53  loss: 0.0655 (0.1456)  time: 0.1012  data: 0.0036  max mem: 3781\n",
            "Epoch: [4]  [200/625]  eta: 0:00:43  loss: 0.0821 (0.1647)  time: 0.1010  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [300/625]  eta: 0:00:33  loss: 0.0883 (0.1615)  time: 0.1011  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [400/625]  eta: 0:00:22  loss: 0.1227 (0.1661)  time: 0.1011  data: 0.0036  max mem: 3781\n",
            "Epoch: [4]  [500/625]  eta: 0:00:12  loss: 0.1257 (0.1628)  time: 0.1010  data: 0.0036  max mem: 3781\n",
            "Epoch: [4]  [600/625]  eta: 0:00:02  loss: 0.1209 (0.1654)  time: 0.1014  data: 0.0037  max mem: 3781\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.1024 (0.1648)  time: 0.1009  data: 0.0036  max mem: 3781\n",
            "Epoch: [4] Total time: 0:01:03 (0.1015 s / it)\n",
            "Averaged stats: loss: 0.1024 (0.1648)\n",
            "Epoch: [5]  [  0/625]  eta: 0:02:08  loss: 0.1513 (0.1513)  time: 0.2062  data: 0.1095  max mem: 3781\n",
            "Epoch: [5]  [100/625]  eta: 0:00:53  loss: 0.0835 (0.1298)  time: 0.1016  data: 0.0040  max mem: 3781\n",
            "Epoch: [5]  [200/625]  eta: 0:00:43  loss: 0.1066 (0.1443)  time: 0.1019  data: 0.0042  max mem: 3781\n",
            "Epoch: [5]  [300/625]  eta: 0:00:33  loss: 0.0633 (0.1362)  time: 0.1013  data: 0.0039  max mem: 3781\n",
            "Epoch: [5]  [400/625]  eta: 0:00:22  loss: 0.1622 (0.1468)  time: 0.1012  data: 0.0036  max mem: 3781\n",
            "Epoch: [5]  [500/625]  eta: 0:00:12  loss: 0.0843 (0.1474)  time: 0.1012  data: 0.0038  max mem: 3781\n",
            "Epoch: [5]  [600/625]  eta: 0:00:02  loss: 0.1202 (0.1501)  time: 0.1012  data: 0.0037  max mem: 3781\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.1045 (0.1498)  time: 0.1011  data: 0.0036  max mem: 3781\n",
            "Epoch: [5] Total time: 0:01:03 (0.1014 s / it)\n",
            "Averaged stats: loss: 0.1045 (0.1498)\n",
            "Test:  [ 0/40]  eta: 0:00:51  loss: 0.6219 (0.6219)  acc1: 84.7656 (84.7656)  acc5: 98.8281 (98.8281)  time: 1.2890  data: 0.7702  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.6110 (0.6157)  acc1: 83.2031 (83.3147)  acc5: 98.8281 (98.9397)  time: 0.5466  data: 0.0314  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.6504 (0.6160)  acc1: 82.8125 (83.1000)  acc5: 98.8281 (99.0200)  time: 0.5228  data: 0.0317  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5548 s / it)\n",
            "* Acc@1 83.100 Acc@5 99.020 loss 0.616\n",
            "Accuracy of the network on the 40 test images: 83.1%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch(\n",
        "        teacher, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch)\n",
        "\n",
        "    if epoch % 10 == 9:\n",
        "        test_stats = evaluate(cifar10_test_loader, teacher, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, teacher, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab509fd",
      "metadata": {
        "id": "9ab509fd"
      },
      "outputs": [],
      "source": [
        "# save finetuned teacher model\n",
        "torch.save(teacher.state_dict(), './teacher.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import utils\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "def train_one_epoch_distillation(teacher, student, criterion,\n",
        "                    data_loader, optimizer,\n",
        "                    device: torch.device, epoch, alpha=1.0, temp=1.0):\n",
        "    teacher.eval()\n",
        "    student.train()\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 100\n",
        "    kl_loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
        "\n",
        "    for samples, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "        samples = samples.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = student(samples)\n",
        "            outputs_teacher = teacher(samples)\n",
        "\n",
        "            # Imeplemet knowledge distillation loss here\n",
        "            # loss = criterion(outputs, F.softmax(outputs_teacher, 0))\n",
        "            loss = kl_loss(F.log_softmax(outputs, 0), F.softmax(outputs_teacher, 0))\n",
        "            # print(loss)\n",
        "\n",
        "            # *****************************************\n",
        "        loss_value = loss.item()\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            sys.exit(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        metric_logger.update(loss=loss_value)\n",
        "\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n"
      ],
      "metadata": {
        "id": "BUeOkGGc5Ts2"
      },
      "id": "BUeOkGGc5Ts2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69587aa8",
      "metadata": {
        "id": "69587aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ecbaff-1e5f-4809-837b-6dcf66fcb924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test:  [ 0/40]  eta: 0:00:50  loss: 0.6219 (0.6219)  acc1: 84.7656 (84.7656)  acc5: 98.8281 (98.8281)  time: 1.2650  data: 0.7541  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:11  loss: 0.6110 (0.6157)  acc1: 83.2031 (83.3147)  acc5: 98.8281 (98.9397)  time: 0.5487  data: 0.0319  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 0.6504 (0.6160)  acc1: 82.8125 (83.1000)  acc5: 98.8281 (99.0200)  time: 0.5264  data: 0.0312  max mem: 3781\n",
            "Test: Total time: 0:00:22 (0.5571 s / it)\n",
            "* Acc@1 83.100 Acc@5 99.020 loss 0.616\n",
            "Accuracy of the network on the 40 test images: 83.1%\n",
            "number of params: 5526346\n",
            "Start training for 5 epochs\n",
            "Epoch: [1]  [  0/625]  eta: 0:02:45  loss: 1.3984 (1.3984)  time: 0.2650  data: 0.1144  max mem: 3781\n",
            "Epoch: [1]  [100/625]  eta: 0:00:31  loss: 1.0820 (1.2168)  time: 0.0578  data: 0.0034  max mem: 3781\n",
            "Epoch: [1]  [200/625]  eta: 0:00:25  loss: 1.0549 (1.1470)  time: 0.0585  data: 0.0036  max mem: 3781\n",
            "Epoch: [1]  [300/625]  eta: 0:00:19  loss: 1.0004 (1.1048)  time: 0.0582  data: 0.0034  max mem: 3781\n",
            "Epoch: [1]  [400/625]  eta: 0:00:13  loss: 0.9127 (1.0648)  time: 0.0593  data: 0.0036  max mem: 3781\n",
            "Epoch: [1]  [500/625]  eta: 0:00:07  loss: 0.8162 (1.0245)  time: 0.0601  data: 0.0035  max mem: 3781\n",
            "Epoch: [1]  [600/625]  eta: 0:00:01  loss: 0.8265 (0.9876)  time: 0.0584  data: 0.0034  max mem: 3781\n",
            "Epoch: [1]  [624/625]  eta: 0:00:00  loss: 0.7675 (0.9797)  time: 0.0602  data: 0.0036  max mem: 3781\n",
            "Epoch: [1] Total time: 0:00:37 (0.0593 s / it)\n",
            "Averaged stats: loss: 0.7675 (0.9797)\n",
            "Test:  [ 0/40]  eta: 0:00:37  loss: 1.6211 (1.6211)  acc1: 46.0938 (46.0938)  acc5: 90.2344 (90.2344)  time: 0.9284  data: 0.7966  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:04  loss: 1.6580 (1.6453)  acc1: 44.1406 (44.0290)  acc5: 91.7969 (91.0342)  time: 0.1654  data: 0.0340  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.6233 (1.6407)  acc1: 43.7500 (44.1700)  acc5: 91.0156 (90.8100)  time: 0.1571  data: 0.0319  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1820 s / it)\n",
            "* Acc@1 44.170 Acc@5 90.810 loss 1.641\n",
            "Accuracy of the network on the 40 test images: 44.2%\n",
            "Epoch: [2]  [  0/625]  eta: 0:02:03  loss: 0.6708 (0.6708)  time: 0.1970  data: 0.1182  max mem: 3781\n",
            "Epoch: [2]  [100/625]  eta: 0:00:31  loss: 0.6732 (0.7516)  time: 0.0586  data: 0.0035  max mem: 3781\n",
            "Epoch: [2]  [200/625]  eta: 0:00:25  loss: 0.6402 (0.7364)  time: 0.0590  data: 0.0035  max mem: 3781\n",
            "Epoch: [2]  [300/625]  eta: 0:00:19  loss: 0.6287 (0.7129)  time: 0.0575  data: 0.0033  max mem: 3781\n",
            "Epoch: [2]  [400/625]  eta: 0:00:13  loss: 0.6390 (0.6973)  time: 0.0580  data: 0.0034  max mem: 3781\n",
            "Epoch: [2]  [500/625]  eta: 0:00:07  loss: 0.5632 (0.6800)  time: 0.0580  data: 0.0034  max mem: 3781\n",
            "Epoch: [2]  [600/625]  eta: 0:00:01  loss: 0.6335 (0.6734)  time: 0.0580  data: 0.0034  max mem: 3781\n",
            "Epoch: [2]  [624/625]  eta: 0:00:00  loss: 0.5648 (0.6704)  time: 0.0584  data: 0.0034  max mem: 3781\n",
            "Epoch: [2] Total time: 0:00:36 (0.0589 s / it)\n",
            "Averaged stats: loss: 0.5648 (0.6704)\n",
            "Epoch: [3]  [  0/625]  eta: 0:01:51  loss: 0.7416 (0.7416)  time: 0.1777  data: 0.1137  max mem: 3781\n",
            "Epoch: [3]  [100/625]  eta: 0:00:31  loss: 0.5277 (0.5682)  time: 0.0585  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [200/625]  eta: 0:00:25  loss: 0.4581 (0.5466)  time: 0.0585  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [300/625]  eta: 0:00:19  loss: 0.5211 (0.5541)  time: 0.0582  data: 0.0033  max mem: 3781\n",
            "Epoch: [3]  [400/625]  eta: 0:00:13  loss: 0.4981 (0.5420)  time: 0.0581  data: 0.0033  max mem: 3781\n",
            "Epoch: [3]  [500/625]  eta: 0:00:07  loss: 0.4838 (0.5400)  time: 0.0583  data: 0.0033  max mem: 3781\n",
            "Epoch: [3]  [600/625]  eta: 0:00:01  loss: 0.4192 (0.5308)  time: 0.0584  data: 0.0034  max mem: 3781\n",
            "Epoch: [3]  [624/625]  eta: 0:00:00  loss: 0.3876 (0.5266)  time: 0.0588  data: 0.0039  max mem: 3781\n",
            "Epoch: [3] Total time: 0:00:36 (0.0590 s / it)\n",
            "Averaged stats: loss: 0.3876 (0.5266)\n",
            "Test:  [ 0/40]  eta: 0:00:36  loss: 1.1341 (1.1341)  acc1: 61.7188 (61.7188)  acc5: 95.3125 (95.3125)  time: 0.9154  data: 0.7745  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:04  loss: 1.0432 (1.0570)  acc1: 65.2344 (65.1972)  acc5: 96.0938 (95.8891)  time: 0.1648  data: 0.0328  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.0686 (1.0537)  acc1: 64.0625 (65.2800)  acc5: 96.0938 (95.8100)  time: 0.1580  data: 0.0323  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1816 s / it)\n",
            "* Acc@1 65.280 Acc@5 95.810 loss 1.054\n",
            "Accuracy of the network on the 40 test images: 65.3%\n",
            "Epoch: [4]  [  0/625]  eta: 0:01:53  loss: 0.2757 (0.2757)  time: 0.1810  data: 0.1097  max mem: 3781\n",
            "Epoch: [4]  [100/625]  eta: 0:00:31  loss: 0.4876 (0.4653)  time: 0.0600  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [200/625]  eta: 0:00:25  loss: 0.4236 (0.4612)  time: 0.0586  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [300/625]  eta: 0:00:19  loss: 0.3924 (0.4583)  time: 0.0589  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [400/625]  eta: 0:00:13  loss: 0.4585 (0.4567)  time: 0.0579  data: 0.0034  max mem: 3781\n",
            "Epoch: [4]  [500/625]  eta: 0:00:07  loss: 0.4534 (0.4552)  time: 0.0595  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [600/625]  eta: 0:00:01  loss: 0.3876 (0.4529)  time: 0.0583  data: 0.0035  max mem: 3781\n",
            "Epoch: [4]  [624/625]  eta: 0:00:00  loss: 0.3253 (0.4506)  time: 0.0581  data: 0.0034  max mem: 3781\n",
            "Epoch: [4] Total time: 0:00:36 (0.0590 s / it)\n",
            "Averaged stats: loss: 0.3253 (0.4506)\n",
            "Epoch: [5]  [  0/625]  eta: 0:01:49  loss: 0.5775 (0.5775)  time: 0.1757  data: 0.1102  max mem: 3781\n",
            "Epoch: [5]  [100/625]  eta: 0:00:31  loss: 0.4080 (0.3941)  time: 0.0573  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [200/625]  eta: 0:00:25  loss: 0.3123 (0.4013)  time: 0.0574  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [300/625]  eta: 0:00:19  loss: 0.3758 (0.4055)  time: 0.0586  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [400/625]  eta: 0:00:13  loss: 0.3984 (0.4075)  time: 0.0587  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [500/625]  eta: 0:00:07  loss: 0.3803 (0.4097)  time: 0.0584  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [600/625]  eta: 0:00:01  loss: 0.3789 (0.4095)  time: 0.0580  data: 0.0034  max mem: 3781\n",
            "Epoch: [5]  [624/625]  eta: 0:00:00  loss: 0.4042 (0.4093)  time: 0.0579  data: 0.0034  max mem: 3781\n",
            "Epoch: [5] Total time: 0:00:36 (0.0588 s / it)\n",
            "Averaged stats: loss: 0.4042 (0.4093)\n",
            "Test:  [ 0/40]  eta: 0:00:35  loss: 1.0722 (1.0722)  acc1: 64.4531 (64.4531)  acc5: 94.5312 (94.5312)  time: 0.8981  data: 0.7643  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:04  loss: 1.0315 (1.0306)  acc1: 68.3594 (67.8199)  acc5: 96.0938 (95.9077)  time: 0.1672  data: 0.0349  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.0375 (1.0357)  acc1: 66.7969 (67.0400)  acc5: 95.7031 (95.9500)  time: 0.1584  data: 0.0326  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1826 s / it)\n",
            "* Acc@1 67.040 Acc@5 95.950 loss 1.036\n",
            "Accuracy of the network on the 40 test images: 67.0%\n",
            "Test:  [ 0/40]  eta: 0:00:35  loss: 1.0722 (1.0722)  acc1: 64.4531 (64.4531)  acc5: 94.5312 (94.5312)  time: 0.8966  data: 0.7558  max mem: 3781\n",
            "Test:  [20/40]  eta: 0:00:04  loss: 1.0315 (1.0306)  acc1: 68.3594 (67.8199)  acc5: 96.0938 (95.9077)  time: 0.1658  data: 0.0337  max mem: 3781\n",
            "Test:  [39/40]  eta: 0:00:00  loss: 1.0375 (1.0357)  acc1: 66.7969 (67.0400)  acc5: 95.7031 (95.9500)  time: 0.1594  data: 0.0334  max mem: 3781\n",
            "Test: Total time: 0:00:07 (0.1823 s / it)\n",
            "* Acc@1 67.040 Acc@5 95.950 loss 1.036\n",
            "Accuracy of the network on the 40 test images: 67.0%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "teacher = create_model(\n",
        "        'vit_base_patch16_224',\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "teacher = teacher.to(device)\n",
        "teacher.load_state_dict(torch.load('./teacher.pth'))\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, teacher, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "# Train the student\n",
        "for p in teacher.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "MODEL_NAME = 'vit_tiny_patch16_224'\n",
        "\n",
        "model = create_model(\n",
        "        MODEL_NAME,\n",
        "        pretrained=True,\n",
        "        num_classes=10,\n",
        "        img_size=224)\n",
        "device = 'cuda:0' # device = 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "\n",
        "\n",
        "print(f\"Start training for {EPOCHS} epochs\")\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_stats = train_one_epoch_distillation(\n",
        "        teacher, model, criterion, cifar10_training_loader,\n",
        "        optimizer, device, epoch, alpha=2.0, temp=1.0)\n",
        "    if epoch % 2 == 1:\n",
        "        test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "        print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")\n",
        "\n",
        "test_stats = evaluate(cifar10_test_loader, model, criterion, device)\n",
        "print(f\"Accuracy of the network on the {len(cifar10_test_loader)} test images: {test_stats['acc1']:.1f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}